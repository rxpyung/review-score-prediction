{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Analyzing Amazon reviews  \n",
    "\n",
    "The task of this coursework is to perform a score and sentiment analysis in a set of reviews from different fine foods products of Amazon. The data consists of ratings of the comments, headers (review summary) and reviews. The dataset also contains different IDs of products and users initially but they are redundant: only score and text will be processed. Our aim is to find a relation between the vocabulary employed in the review and the degree of acceptance of the product.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for analysis is loaded in the environment. Only score, summary and text is preserved. The structure of the data is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers of the dataset:  ['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'] \n",
      "\n",
      "Example of the initial dataset:  [['1', 'B001E4KFG0', 'A3SGXH7AUHU8GW', 'delmartian', '1', '1', '5', '1303862400', 'Good Quality Dog Food', 'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.'], ['2', 'B00813GRG4', 'A1D87F6ZCVE5NK', 'dll pa', '0', '0', '1', '1346976000', 'Not as Advertised', 'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".']] \n",
      "\n",
      "Example of the final dataset:  [('5', 'Good Quality Dog Food', 'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.')]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Path to the Reviews .csv and load to a RDD\n",
    "path = 'hdfs://saltdean/data/reviews/Reviews.csv'\n",
    "raw_data_RDD = sc.textFile(path).mapPartitions(lambda row: csv.reader(row))\n",
    "\n",
    "# Store the headers, filter the first row and extract score, summary and text\n",
    "headers = raw_data_RDD.first()\n",
    "data_RDD = raw_data_RDD.filter(lambda row: row != headers)\n",
    "reviews_RDD = data_RDD.map(lambda row: (row[6],row[8],row[9]))\n",
    "\n",
    "# Print headers and one example\n",
    "print(\"Headers of the dataset: \",headers,\"\\n\")\n",
    "print(\"Example of the initial dataset: \",data_RDD.take(2),\"\\n\")\n",
    "print(\"Example of the final dataset: \",reviews_RDD.take(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Look inside the dataset\n",
    "\n",
    "Once we have the dataset loaded, it is time to filter out possible missing values. In this particular case, the original dataset is cleaned, but if any pre-filtering operation is needed, it should be applied in the next cell. The final dataset contains roughly half-million reviews and scores. \n",
    "\n",
    "In order to make a deeper analysis in subsequent sections, we preserve the raw score and then, we generate a new sentiment column that labels reviews into positive (4-5 rating), negative (1-2 rating) and neutral(3 rating).\n",
    "\n",
    "After the filtering, downsampling of the dataset have been performed. The classes are clearly imbalanced, the sum of scores 4 and 5 dominates the dataset in a ratio 4:1. As the dataset is big enough as to cut down its size without losing information (theoretically), downsample was the technique selected to solve the imbalancement problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pre-wrangled size of the dataset is:  568454 \n",
      "\n",
      "The post-wrangled size of the dataset is:  568454 \n",
      "\n",
      "The shape of the dataset previously to the analysis is:  [('five', '5', 'Good Quality Dog Food', 'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.', 'positive')]\n"
     ]
    }
   ],
   "source": [
    "# Display the initial number of items\n",
    "print(\"The pre-wrangled size of the dataset is: \",reviews_RDD.count(),\"\\n\")\n",
    "\n",
    "# Remove rows which may contain score non-alphanumeric or empty text\n",
    "possibleScores = ['1','2','3','4','5']\n",
    "reviews_RDD_1 = reviews_RDD.filter(lambda row: row[0] in possibleScores)\n",
    "reviews_RDD_2 = reviews_RDD_1.filter(lambda row: row[1] != '')\n",
    "reviews_RDD_filtered = reviews_RDD_2.filter(lambda row: row[2] != '')\n",
    "\n",
    "# Display the initial number of items\n",
    "print(\"The post-wrangled size of the dataset is: \",reviews_RDD_filtered.count(),\"\\n\")\n",
    "\n",
    "# Now add the name of the score for possible visualizations \n",
    "scoreNames = {'1':\"one\",'2':\"two\",'3':\"three\",'4':\"four\",'5':\"five\"}\n",
    "reviews_RDD_scores = reviews_RDD_filtered.map(lambda row: (scoreNames[row[0]],row[0],row[1],row[2]))\n",
    "\n",
    "# Finally add the sentiment: score 1-2 bad, 3 neutral, 4-5 good\n",
    "reviews_RDD_final = reviews_RDD_scores.map(lambda row: (row[0],row[1],row[2],row[3],\"positive\" if row[1] \n",
    "                                                        in ['4','5'] else \"neutral\" if row[1] == '3' else \"negative\"))\n",
    "                                           \n",
    "print(\"The shape of the dataset previously to the analysis is: \",reviews_RDD_final.take(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result after filtering part of the positive labels:  [('five', '5', 'Good Quality Dog Food', 'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.', 'positive')]\n",
      "\n",
      "The size of the dataset after downsampling is:  213435\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Undersampling of the dataset (scores 4 and 5)\n",
    "reviews_RDD_filtered = reviews_RDD_final.filter(lambda row: (row[4]!=\"positive\") | (np.random.rand(1) > 0.8))\n",
    "\n",
    "# Show the result\n",
    "print(\"Result after filtering part of the positive labels: \",reviews_RDD_filtered.take(1))\n",
    "\n",
    "# Show the dataset after downsampling\n",
    "print(\"\\nThe size of the dataset after downsampling is: \",reviews_RDD_filtered.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Convert the dataset to a DataFrame\n",
    "\n",
    "After the pre-processing, we will parse the dataset into a Spark DataFrame to carry out the analysis. DataFrames are column-based structures prepared to perform data analysis and create machine learning algorithms in an easier and more comprehensive way. Although the RDD can be used for analysis as well, DataFrames are more structured to apply models and statistical methods smoothly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "chartsize": "57",
      "handlerId": "barChart",
      "keyFields": "sentiment",
      "sortby": "Keys ASC"
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n",
       "        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n",
       "            \n",
       "        </div>\n",
       "    <div id=\"chartFiguree5bdc9c4\" class=\"pd_save is-viewer-good\" style=\"overflow-x:auto\">\n",
       "            \n",
       "                    \n",
       "                            <center><img style=\"max-width:initial !important\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAa0AAAEoCAYAAADrK65cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAOwwAADsMBx2+oZAAAIABJREFUeJzt3Xl4VOX9/vH3TCDBLJOFnQRkFYG0JkjAhi2xYS2yaYoVZEclZZGGtPanEjZbvkKgIIooYhShloCIFZoUy1pAjRqgiQVBQBBUliRMQoCEzPn9QTM6QMIWGA5zv65rLj3nec7nPLNkbs4y51gMwzAQERExAau7ByAiInK1FFoiImIaCi0RETGNKu4egMj1Kioq4tChQ5SWlrp7KHILeXl50aBBA3x9fd09FHEDhZaYjmEYTJgwgblz57p7KOJG48ePZ86cOVgsFncPRW4hhZaYzoQJE5g/fz7z5s2jQ4cOeHt7u3tIcgsVFxfz73//mwkTJpCbm8ucOXMICQlReHkIhZaYSlFREXPnzmXevHmMHTvW3cMRN4mMjARg3LhxhIeHExUVRadOnfDy8nLzyORm04kYYiqHDh0CoEOHDm4eibhb2WfgzJkzfPbZZ+zdu9fNI5JbQaElplJ20oV2CUrZZ+Cuu+7CMAznP2jkzqbQEhHTq1q1KgUFBe4ehtwCOqYld4yjR4+Sl5fntvUHBwdTr169W77eyZMnM3XqVBwOxy1f980wZcoUOnfuTExMjLuHIrchhZbcEY4ePUqzZs0pKip02xh8ff3Zu3fPLQ8ui8VyR505N2XKFJ577jmFllyWQkvuCHl5ef8LrEeBEDeMIJeionfJy8tzy9aWiKfQMS25w4QAtdzwuLGgnDx5MlarlezsbB588EH8/PyoV68eycnJLv2ysrLo2LEjd911F/Xr12f69Olc740aXn/9de6//358fX0JCQkhNjaWjz/+2Nn+/fffM3jwYGrWrEm1atW47777WLp06WXHfbGhQ4fSqFEj5/Q333yD1WrltddeIzk5mXr16hEcHEzv3r05cuSIs5/VasVisTB9+nSsViteXl5MnTr1up6f3Jm0pSVyGyjbvdevXz+GDx/O//t//4+MjAymTZuGl5cXkyZN4uTJkzz44IPUq1ePJUuW4O3tzcyZM/nmm2+ueX0TJ05k9uzZjBo1iqlTp2K1Wvn44485dOgQDzzwAEVFRXTq1IlTp04xY8YMwsLCeOedd3j88cc5c+YMI0eOdI77crsmy5s/Y8YMoqOjefPNNzl27Bi/+93vGDRoEBs2bADg448/5oEHHmDYsGE8+eSTAISFhV3z85M7l0JL5DZhsVh44oknSEpKAiAuLo5Tp06RkpLC008/zezZszlz5gz//Oc/CQ0Ndfa5++67r2k9X3/9NX/5y19ITExk5syZzvk9evRw/v/ixYv5+uuv2bhxIx07dgSgW7dufP/99zz33HOMGDHiuo6jNWzYkHfeecc5fezYMX7/+9/z/fffU6dOHdq2bQtAaGio8/9Ffkq7B0VuI/Hx8S7Tjz76KIWFhWRnZzu3QsoCC8DX15eHHnromtbx0UcfYRgGo0aNKrfPli1bCA0NdQZWmUGDBnH8+HG+/PLLa1pnmZ49e7pM/+xnPwPQb6zkqim0RG4jtWvXvuz0kSNH+O677y5pv9wyV3Ly5Emg4t1uubm51K1b95L5derUcbZfj5AQ12N/Pj4+AJw9e/a66onnUWiJ3EZ++OGHy06HhoZSt27dS9rhwgkT16JGjRoALidAXCwkJOSydcvmVa9eHYBq1aoBcP78eZd+ZcEoUtkUWiK3keXLl7tM//Wvf8Xf35/w8HB+8Ytf8PHHH7uEzenTp/nwww+vaR1xcXFYLBZee+21cvt07tyZb7/9lu3bt7vMX7p0KbVq1aJFixYAzuNp2dnZzj75+fls27btmsb0U97e3pw5c+a6l5c7m07EELlNGIbB66+/TmlpKVFRUaSnp7N48WKmTJmCzWZjwoQJvPLKK3Tp0oXJkyfj7e3NrFmzuOuuu65pPY0bN2bChAnMmTMHu91O79698fLy4tNPP6VFixbEx8czdOhQ5s6dS//+/Zk+fbrz7MF//etfvPbaa86TMHr06IHNZmPUqFFMnjyZs2fPMnPmTPz9/a/pef9Uy5YtWbNmDd26dXNeZeRyuyrFM2lLS+4wucAxNzyu7xjPT1ksFlavXs26devo06cPy5Yt4/nnn+e5554DLuySW79+PTVr1mTo0KGMHTuWHj16MGLEiGte18yZM3nllVf45JNPeOSRRxg0aBAbN26kQYMGwIUTPDZv3kzXrl354x//SN++ffnPf/7DO++847K+wMBA1qxZg9VqZcCAATz77LOMGzeOBx988LLPr7zn/VMvv/wyfn5+9O7dm7Zt2/L6669f8/OTO5fFuN5fJoq4QU5ODuHh4WRnZ9OqVSvnfLNfxmnKlClMnTqVkpKSy/5YVy5V9ln4v//7P6pWrUqDBg14+OGH3T0sucm0e1DuCPXq1WPv3j0eecFcEU9SYWjl5+fzhz/8gTVr1mC32/nFL37BvHnzaN68OQCHDx8mISGBTZs2Ua1aNQYMGMCcOXOoUuXHsi+//DKzZs3i+PHj3HvvvcyZM8fltx+VUUMELgSXmUOjMi56axhGhVd7t1gs2pITU6vw0ztkyBAOHz7Mf/7zH06cOEHLli3p0qULZ86cwTAMfvWrX1GjRg2+++47Pv/8czZv3uz8NT9AWloazz33HEuWLCE/P5/hw4fTs2dP59lPlVFD5E6QnJzM+fPnbzhQhg8fTtWqVct9xMXFVdKIRdyj3GNaZ86cISAggO3btxMVFQXAuXPn8Pf35+233yY0NJQuXbrw/fffExwcDMAHH3zAwIEDyc3NpWrVqjz44INERkaSkpLirNu6dWsefvhhnn32WTZt2kTXrl1vqIZ4lvKOackFhw4d4sSJE+W2BwQE0KxZs1s4optHx7Q8U7m7Bx0OxyW7GsrmffHFFxw/fpzGjRs7wwYgKiqK06dPs2fPHsLDw9mxY4fzopc/7ZOVlQXAzp07b7iGiPyoQYMGzjMARe5E5YaWn58fcXFxTJo0iSVLluDn58czzzwDgN1ux263ExQU5LJMWfjY7Xbnfy/X58CBAxW2X0uNi+Xn57Np0ybq16/vvESM3Dn27dvn7iHIbSY3NxcfHx+8vb3Jyclx93CkEp07d47Dhw/TuXNnZw5UeCLG0qVLSUpK4v7778fhcDBq1CiaN29OjRo1sNls5Ofnu/QvO3MrMDAQoNw+NputwvZrqXGxTZs20bdv34qeltwBLr5skHiekpISAP72t78RGBhIYWEhY8aMcfOo5GZ4//336dOnD3CF0KpRowZvvvmmc/r48eO8+OKLxMXF4eXlxYEDB8jLy3NuHWVmZuLn5+fcZx4REUFmZiYDBgxw1vjss8/o37+/s/1Ga1ysfv36zifZtGnTa3hZzC8xMdHl2N+d6NSpU7Rv357vv/+e++67z93DETcquw7iE088wdmzZ6lVqxYxMTHuHdRN5Al/3xfbt28fffv2dX6vwxVC66uvviI4OJiaNWuyb98+EhISiIuLIzY2FsMwuPfee0lMTGTevHnk5uaSnJzMyJEj8fb2BiAhIYEnnniCvn370q5dOxYtWsTevXsZOnQoAB07drzhGhcr2yXYtGlTjztQb7PZ7vjnbBgGoaGhrFixgm7durl7OOJGaWlp1KhRgwYNGnDs2DHq1Klz0z//R48edetvAd3F3b9B/OmhngpDa+vWrUyaNIm8vDyqV6/OY489xpQpU4ALv/f4+9//zujRo6lbty7VqlXjscce48UXX3Qu/8gjj3Ds2DHnPXhatGjB2rVrnfcDqowa4lksFgszZsxg8ODBtGrVitjYWJff9Mmd7/z582zYsIE333yT0aNHY7FYcDgcVK1a9aau93a46kpGRoZb1nsjV3upbHfcZZw8+ZToX//615dcJfxOZBgGTz/9NK+99pruw+ShfHx8iImJ4fHHH8fhcPDtt9/StWtX7r///pu2zrLvFngUCLlS95sgA3DH3oVc4F23fKde7vtc/0S9g1x819s7lcViYe7cuYwbN4533nmHvLw8jzxT9LvvvvPIq59brVYCAwOpVq0aP/zwA+fOnSMsLOwW/v4sBKh1i9b1U63dtN7bi0LrDuIpoVWmSZMmJCQksHfvXo4ePUppaam7hyS3mLe3N2FhYTRv3rzcM4rvHJ6156g8Ci0xtZo1a1KzZk13D0NEbhFdOVNERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImIZCS0RETEOhJSIipqHQEhER09C1ByuZbhInInLzVBhax44d4+mnn2b9+vUUFxfTokUL/vznP9OpUycANm7cSGJiIrt376ZOnTokJSXx1FNPOZcvLi5mwoQJLF++nOLiYjp37swrr7xCWFiYs09l1Lhd3A43iXOX2+kmcSJy56owtEaPHs2JEyf48ssvCQ4OZs6cOfTq1YtDhw5x6tQpevXqxaxZsxg5ciTbtm2jd+/e1K1blz59+gAwYcIEtm7dSlZWFkFBQfz2t7+ld+/efPHFFwAcOnTohmvcTvLy8v4XWO66SZy75FJU9C55eXkKLRG5qSoMra+//poRI0YQEnLhC/jJJ59k4sSJ7N27l3/84x80b97cuVXUqVMnhg8fzvz58+nTpw/nzp0jNTWVv/3tb86totmzZ1O3bl22bt1K+/btSU1NveEatyd33SROROTOVuGJGH/4wx9YtWoV33//PSUlJcyfP59mzZrx85//nB07dtC2bVuX/lFRUWRlZQGwe/duzp49S1RUlLO9evXqNGrUyNmnMmqIiIjnqDC02rdvT7Vq1ahXrx5+fn7MmTOH1NRUfHx8sNvtBAUFufQPDg7GbrcDUFBQAFBhn8qoISIinqPc3YOGYRAbG0tMTAx5eXkEBATw4Ycf0qNHDzZt2oTNZiM/P99lmby8POctr8v+m5+fT+3atcvtc6M1ypOYmOjSJz4+3uNuRy8iYiZpaWmkpaU5py+3cVJuaOXl5XHgwAHee+89AgMDAejduzdNmjThn//8JxEREaxevdplmczMTCIjIwFo3rw51apVIzMzk169egFw4sQJDh48SOvWrQGIiIjggw8+uK4aZX3Kk5KSQqtWrSrsIyIit4+LNy5ycnLIyMhw6VPu7sGQkBBatGjByy+/TEFBAYZh8OGHH/Lll1/Spk0bhg4dyp49e1i4cCElJSVs2bKFN998kzFjxgDg4+PDsGHDmDRpEocPH6agoIDExETCw8OJjo4GYOjQoezevfu6aty+J2GIiMjNUuExrQ8++IDjx4/TtGlTgoOD+eMf/8j8+fOJjY2lQYMGrF27loULFxIUFMSQIUOYMWOG81R1uHCmX/v27YmMjCQ0NJTc3FyXLavKqCEiIp6jwlPemzRpwqpVq8pt79SpU4W/l/L29uall17ipZdeuqk1RETEM+jagyIiYhoKLRERMQ2FloiImIZCS0RETEOhJSIipqHQEhER01BoiYiIaSi0RETENBRaIiJiGgotERExDYWWiIiYhkJLRERMQ6ElIiKmodASERHTKDe0wsPDsdlszoefnx9Wq9V5t+Jdu3bRuXNn/P39CQsLY8qUKZfUSE5OJjQ0lICAAGJiYsjJyXFpr4waIiLiOcoNrezsbOx2u/MxY8YMatSoQY8ePSgsLKR79+507NiR3Nxc0tPTWbRoEXPnznUuP3PmTFJTU1m3bh0nTpwgOjqabt26UVRUBFApNURExLNc9e7BV199lZEjR+Lt7c3KlStxOBxMnToVb29vwsPDSUpKYv78+c7+CxYsICkpiZYtW+Lj48O0adMoLi523lSyMmqIiIhnuarQWr9+PV999RVPPfUUADt37iQyMhKr9cfFo6Ki2L9/P4WFhdjtdg4ePEhUVJSz3cvLi8jISLKysiqthoiIeJYqV9NpwYIFdO/enQYNGgBgt9sJCgpy6RMcHOxsczgcAJftY7fbK62GiIh4liuG1nfffcfq1av54IMPnPNsNhtHjhxx6ZeXl+dsKwuc/Pz8S/qEhYVVWg0REfEsVwythQsXUr9+fbp37+6cFxERwbJly3A4HM7de5mZmTRu3Bh/f38AGjZsSGZmJu3atQOgtLSUHTt2MGTIkBuuMXjw4Cs+scTERGw2m3M6Pj6e+Pj4K78iIiLiFmlpaaSlpTmnL7dXrcJjWqWlpSxatIjRo0e7zO/fvz9eXl4kJydz9uxZsrOzSUlJYcyYMc4+CQkJzJo1i5ycHM6cOcOkSZPw9vamb9++N1yjX79+V3zyKSkpLF++3PlQYImI3N7i4+NdvrdTUlIu6VPhltbq1avJzc1l+PDhLvP9/f3JyMggISGB2bNnExgYyOjRoxk/fryzz8SJEyksLCQuLo6CggLatGlDeno6vr6+lVZDREQ8S4Wh1b9//3J/ExUeHs7mzZsrLD558mQmT55cbntl1BAREc+hyziJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImIZCS0RETEOhJSIipnHF0Nq+fTu//OUvsdlsBAcH06FDB2fbrl276Ny5M/7+/oSFhTFlypRLlk9OTiY0NJSAgABiYmLIyclxaa+MGiIi4hkqDK3t27fTs2dPhg0bxvHjxzl58iRz5swBoLCwkO7du9OxY0dyc3NJT09n0aJFzJ0717n8zJkzSU1NZd26dZw4cYLo6Gi6devmvLFkZdQQERHPUWFo/eEPf2DkyJEMGjQIHx8frFYrUVFRAKxcuRKHw8HUqVPx9vYmPDycpKQk5s+f71x+wYIFJCUl0bJlS3x8fJg2bRrFxcWsWrWq0mqIiIjnKDe0zpw5w7Zt27BarbRr144aNWoQFRXFe++9B8DOnTuJjIzEav2xRFRUFPv376ewsBC73c7BgwedIQfg5eVFZGQkWVlZlVZDREQ8R5XyGnJzc3E4HLz99tusWbOGiIgIVq9ezaOPPsqmTZuw2+0EBQW5LBMcHAyA3W7H4XAAXLaP3W539rvRGiIi4jnKDa2AgAAAhg0bRuvWrQHo168fsbGxrF69GpvNxpEjR1yWycvLA8BmszkDJz8//5I+YWFhzn43WqM8iYmJ2Gw253R8fDzx8fEVLiMiIu6TlpZGWlqac/pyGyflhpbNZqNJkyblFo+IiGDZsmU4HA7n7r3MzEwaN26Mv78/AA0bNiQzM5N27doBUFpayo4dOxgyZMgN1xg8eHCFTz4lJYVWrVpV2EdERG4fF29c5OTkkJGR4dKnwhMxxo4dS2pqKjt37sQwDD744AM2b97Mww8/TP/+/fHy8iI5OZmzZ8+SnZ1NSkoKY8aMcS6fkJDArFmzyMnJ4cyZM0yaNAlvb2/69u0LcEM1+vXrVykvkoiImEe5W1oA48aN48yZMzz00EOcOnWKZs2asXz5ctq0aQNARkYGCQkJzJ49m8DAQEaPHs348eOdy0+cOJHCwkLi4uIoKCigTZs2pKen4+vrC4C/v/8N1xAREc9hMQzDcPcgKlNOTg7h4eFkZ2ff8t2DZeuGBKDWLV23ex0DXnHLay5yq+jv233fqT9dty7jJCIipqHQEhER01BoiYiIaSi0RETENBRaIiJiGgotERExDYWWiIiYhkJLRERMQ6ElIiKmodASERHTUGiJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJhGuaE1ZcoUqlSpgs1mIyAgAJvNxsCBA53tu3btonPnzvj7+xMWFsaUKVMuqZGcnExoaCgBAQHExMSQk5Pj0l4ZNURExHNUuKUVHR2N3W6noKAAu93O0qVLASgsLKR79+507NiR3Nxc0tPTWbRoEXPnznUuO3PmTFJTU1m3bh0nTpwgOjqabt26UVRUVGk1RETEs1zX7sGVK1ficDiYOnUq3t7ehIeHk5SUxPz58519FixYQFJSEi1btsTHx4dp06ZRXFzMqlWrKq2GiIh4lgpDKysri9q1a9OoUSMGDhzIwYMHAdi5cyeRkZFYrT8uHhUVxf79+yksLMRut3Pw4EGioqKc7V5eXkRGRpKVlVVpNURExLOUG1rx8fF8+eWX/PDDD2zbtg2LxUKXLl0oKirCbrcTFBTk0j84OBgAu92O3W4HuGyfsrbKqCEiIp6lSnkNLVu2dP5/3bp1Wbx4MYGBgWzbtg2bzcaRI0dc+ufl5QFgs9lwOBwA5OfnX9InLCzM2e9Ga1QkMTERm83mnI6Pjyc+Pv6Ky4mIiHukpaWRlpbmnL7cBkq5oXU5FosFwzCIiIhg2bJlOBwO5+69zMxMGjdujL+/PwANGzYkMzOTdu3aAVBaWsqOHTsYMmQIwA3VGDx48BXHmpKSQqtWra7l6YmIiBtdvHGRk5NDRkaGS59ydw+mpaVx8uRJAH744QdGjhxJnTp1iI6Opn///nh5eZGcnMzZs2fJzs4mJSWFMWPGOJdPSEhg1qxZ5OTkcObMGSZNmoS3tzd9+/YFuKEa/fr1q5xXSERETKXc0HrnnXdo2bIl/v7+tGnThtLSUj766CP8/Pzw9/cnIyODTZs2Ub16dbp27crIkSMZP368c/mJEycydOhQ4uLiqFmzJlu3biU9PR1fX1+ASqkhIiKepdzdg6tXr65wwfDwcDZv3lxhn8mTJzN58uSbWkNERDyHLuMkIiKmodASERHTUGiJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDSu6X5aIuLq6NGjzpuXepLg4GDq1avn7mGIB1JoiVyno0eP0qxZc4qKCt09lFvO19efvXv3KLjkllNoiVynvLy8/wXWo0CIu4dzC+VSVPQueXl5Ci255a76mFa/fv2wWq2sX7/eOW/jxo3cf//9+Pn50aRJE1599VWXZYqLi/ntb39LzZo1CQwMpHfv3nz77bcufSqjhoh7hQC1POjhSQEtt5urCq23336boqIiLBaLc94333xDr169GDVqFKdOneLNN9/kmWeecbl55IQJE9i6dStZWVkcOXKE4OBgevfu7Ww/dOjQDdcQERHPccXQ+vbbb5k0aRJvvPEGhmE457/11ls0b96cp556iipVqtCpUyeGDx/O/PnzATh37hypqalMnz6dsLAw/P39mT17NtnZ2WzduhWA1NTUG64hIiKe44qhNWLECJ5//nnCwsJc5u/YsYO2bdu6zIuKiiIrKwuA3bt3c/bsWaKiopzt1atXp1GjRs4+lVFDREQ8R4Wh9corrwAXgqtM2S5Cu91OUFCQS//g4GDsdjsABQUFABX2qYwaIiLiOco9e3D//v1Mnz6dTz75xGV+2S5Cm81Gfn6+S1teXh42m83ZDpCfn0/t2rXL7XOjNcqTmJjo0ic+Pp74+PgKlxEREfdJS0sjLS3NOX25jZNyQ2vLli3k5uZy//33uxzLevjhhxkwYACRkZG8//77LstkZmYSGRkJQPPmzalWrRqZmZn06tULgBMnTnDw4EFat24NQEREBB988MF11SjrU56UlBRatWpVYR8REbl9XLxxkZOTQ0ZGhkufcncPDhgwgP3797Njxw527tzJzp07AXjttdeYMWMGQ4YMYc+ePSxcuJCSkhK2bNnCm2++yZgxYwDw8fFh2LBhTJo0icOHD1NQUEBiYiLh4eFER0cDMHToUHbv3n1dNdq3b1+5r5aIiNz2yg2tatWqUa9ePZeHxWKhevXqBAUF0aBBA9auXcvChQsJCgpiyJAhzJgxgz59+jhrzJ49m/bt2xMZGUloaCi5ubkuW1aVUUNERDzHNV0Ro7S01GW6U6dOfPHFF+X29/b25qWXXuKll14qt09l1BAREc+gq7yLiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImIZCS0RETEOhJSIiplFuaE2dOpWmTZsSFBRErVq16NGjh/PuxWV27dpF586d8ff3JywsjClTplxSJzk5mdDQUAICAoiJiSEnJ6fSa4iIiGcoN7R+85vf8Pnnn5Ofn8/Ro0fp0qUL3bp1wzAMAAoLC+nevTsdO3YkNzeX9PR0Fi1axNy5c501Zs6cSWpqKuvWrePEiRNER0fTrVs3ioqKKq2GiIh4jnJDq1mzZgQGBgIX7lhstVo5fvw4ubm5AKxcuRKHw8HUqVPx9vYmPDycpKQk5s+f76yxYMECkpKSaNmyJT4+PkybNo3i4mJWrVpVaTVERMRzVHhMa+3atQQHB3PXXXcxceJEfve731G9enUAdu7cSWRkJFbrjyWioqLYv38/hYWF2O12Dh48SFRUlLPdy8uLyMhIsrKyKq2GiIh4jioVNfbs2ZO8vDzy8/N56623CAsLc7bZ7XaCgoJc+gcHBzvbHA4HwGX72O32SqshIiKeo8LQKhMUFMS4ceMIDg7mnnvu4Wc/+xk2m40jR4649MvLywPAZrM5Ayc/P/+SPmXhVxk1ypOYmIjNZnNOx8fHEx8ffzVPV0RE3CAtLY20tDTn9OU2Tq4qtODCca2SkhL27t3Lz372MyIiIli2bBkOh8O5ey8zM5PGjRvj7+8PQMOGDcnMzKRdu3bOGjt27GDIkCEAN1Rj8ODBFY43JSWFVq1aXe3TExERN7t44yInJ4eMjAyXPuUe05o3bx7Hjh0D4Pjx4yQkJODj40P79u0B6N+/P15eXiQnJ3P27Fmys7NJSUlhzJgxzhoJCQnMmjWLnJwczpw5w6RJk/D29qZv3743XKNfv36V8BKJiIiZlBta69at47777iMgIICIiAiOHTvGRx99RO3atQHw9/cnIyODTZs2Ub16dbp27crIkSMZP368s8bEiRMZOnQocXFx1KxZk61bt5Keno6vr2+l1RAREc9R7u7Bv//971dcODw8nM2bN1fYZ/LkyUyePPmm1hAREc/oC+mpAAAURUlEQVSgyziJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImIZCS0RETKPc0PrjH//Iz3/+cwIDAwkNDeWxxx7j22+/delz+PBhHnroIWw2G7Vq1WLs2LGcP3/epc/LL79Mo0aN8Pf3p02bNmzZsqXSa4iIiGcoN7SsVitvvfUWJ0+e5L///S8Wi4WHHnrI2W4YBr/61a+oUaMG3333HZ9//jmbN28mKSnJ2SctLY3nnnuOJUuWkJ+fz/Dhw+nZsydHjhyptBoiIuI5yg2tF154gcjISKpUqYLNZuP3v/89u3bt4tSpUwBs3ryZPXv2MHv2bPz8/Khfvz7Tpk1j0aJFlJSUALBgwQKGDx9Ohw4dqFKlCgkJCTRr1ozU1NRKqyEiIp7jqo9pZWRkcPfddxMYGAjAzp07ady4McHBwc4+UVFRnD59mj179gCwY8cO2rZt61InKiqKrKysSqshIiKe46pC66OPPmLatGksXLjQOc9utxMUFOTSryx87HZ7hX2u1H4tNURExHNcMbQ+/PBD4uPjWbp0KV26dHHOt9ls5Ofnu/TNy8sDcG6NldfHZrNVWg0REfEcVSpqXLp0KWPGjCEtLY24uDiXtoiICA4cOEBeXp5z6ygzMxM/Pz+aNWvm7JOZmcmAAQOcy3322Wf079+/0mqUJzEx0SXY4uPjiY+Pr/jVEBERt0lLSyMtLc05fbk9auWG1vz583n++ef58MMPad++/SXtHTt25N577yUxMZF58+aRm5tLcnIyI0eOxNvbG4CEhASeeOIJ+vbtS7t27Vi0aBF79+5l6NChlVajPCkpKbRq1eqKL5KIiNweLt64yMnJISMjw6VPuaE1btw4qlatSo8ePYALp6dbLBb+8Y9/0L59eywWC3//+98ZPXo0devWpVq1ajz22GO8+OKLzhqPPPIIx44dY9CgQRw/fpwWLVqwdu1aQkNDASqlhoiIeI5yQ8vhcFxx4fr16/Phhx9W2CchIYGEhISbWkNERDyDLuMkIiKmodASERHTUGiJiIhpKLRERMQ0FFoiImIaCi0RETENhZaIiJiGQktERExDoSUiIqah0BIREdNQaImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImEa5ofW3v/2NTp06ERgYiJeX1yX319q1axedO3fG39+fsLAwpkyZckmN5ORkQkNDCQgIICYmhpycnEqvISIinqPc0AoJCeG3v/0tf/nLXy5pKywspHv37nTs2JHc3FzS09NZtGgRc+fOdfaZOXMmqamprFu3jhMnThAdHU23bt0oKiqqtBoiIuJZyg2tLl26MGDAABo3bnxJ28qVK3E4HEydOhVvb2/Cw8NJSkpi/vz5zj4LFiwgKSmJli1b4uPjw7Rp0yguLmbVqlWVVkNERDzLdR3T2rlzJ5GRkVitPy4eFRXF/v37KSwsxG63c/DgQaKiopztXl5eREZGkpWVVWk1RETEs1S5noXsdjtBQUEu84KDg51tZce/LtfHbrdXWg0REfEs1xVaNpuNI0eOuMzLy8tztpUFTn5+/iV9wsLCKq1GRRITE7HZbM7p+Ph44uPjr7iciIi4R1paGmlpac7py22gXFdoRUREsGzZMhwOh3P3XmZmJo0bN8bf3x+Ahg0bkpmZSbt27QAoLS1lx44dDBky5IZrDB48+IpjTElJoVWrVtfz9ERExA0u3rjIyckhIyPDpU+5x7QcDgfnzp3j3LlzAJw9e5Zz585hGAb9+/fHy8uL5ORkzp49S3Z2NikpKYwZM8a5fEJCArNmzSInJ4czZ84wadIkvL296du3L8AN1ejXr1/lvEIiImIq5YbWkiVLuOuuu+jRowcA/v7++Pr6smXLFvz9/cnIyGDTpk1Ur16drl27MnLkSMaPH+9cfuLEiQwdOpS4uDhq1qzJ1q1bSU9Px9fX11nvRmuIiIhnKXf34JAhQ5y78i4nPDyczZs3V1h88uTJTJ48+abWEBERz6HLOImIiGkotERExDQUWiIiYhoKLRERMQ2FloiImIZCS0RETEOhJSIipqHQEhER01BoiYiIaSi0RETENBRaIiJiGgotERExDYWWiIiYhkJLRERMQ6ElIiKmYZrQSk5OJjQ0lICAAGJiYsjJyXH3kG5Dek08i95vz6L3G0wSWjNnziQ1NZV169Zx4sQJoqOj6datG0VFRe4e2m1GH2rPovfbs+j9BpOE1oIFC0hKSqJly5b4+Pgwbdo0iouLWbVqlbuHJiIit9BtH1p2u52DBw8SFRXlnOfl5UVkZCRZWVluHJmIiNxqVdw9gCux2+0ABAUFucwPDg52tv3UuXPnANi3b9/NH9xFflznASD3lq8fCoDdbljvKcA9r7k76f3W+31red77XbbOsu91AIzb3KlTpwyLxWJ8/PHHLvO7du1qJCYmXtL//fffNwA99NBDDz3ukMf777/v/I6/7be0bDYbDRs2JDMzk3bt2gFQWlrKjh07GDx48CX9O3fuzPvvv0/9+vXx8fG51cMVEZFKcu7cOQ4fPkznzp2d8yyGYRhuHNNVmTVrFvPnz2fNmjU0btyY6dOn8/bbb7Nnzx58fX3dPTwREblFbvstLYCJEydSWFhIXFwcBQUFtGnThvT0dAWWiIiHMcWWloiICJjglHcREZEyCi0PFB4ezpIlS9w9DLnNbNq0CavVisPhcPdQ5H8OHz6MzWbj4MGDFfYLCAhg8+bNt2ZQbqbQuoOV9yWUnZ3N448/7qZRSWWaMmUKHTt2rLR6Foul0mrJjatfvz52u52GDRsC8NZbb1G/fv1L+hUUFNCpU6dbPDr3UGjdwQzDwGKxoMOWd7arCZrS0tJbMBK52cr+pj2ZQusmio2N5emnn2bgwIEEBQVx99138+qrrzrbP/nkE2JjY6lRowaNGjVi0qRJLltFn376KW3btiUwMJC2bdsyZ84crNYf37JNmzbRvn17atSoQfXq1fnlL3/Jzp07gQu7FXr27AlcuJqIzWZjxowZADRq1IjFixcDEB0dzQsvvOAy7pUrV1KrVi3Onz9/VeOU8t3IZ+Cbb77BarWyf/9+Z/+fbj0vW7aMP/3pT2zfvp2AgABsNhtbt251Lrd48WIiIiLw8/Pj888/r/DzIjcmNjaWsWPH8vDDD2Oz2WjevLnLLvg1a9YQFRVFUFAQ9957LykpKc5/TJaUlJCQkEDdunUJDAykcePGvPzyy4DrZ+Df//43o0eP5ujRo873+69//SsAVquV9evX43A4aNCgAUuXLnUZX0pKCpGRkc7ptWvX8sADDxASEkLz5s156aWXbvZLVHlu2qUsxIiJiTGCgoKMjRs3GoZhGCtXrjS8vLyMr7/+2ti9e7cREBBgLF++3HA4HMahQ4eMiIgI409/+pNhGBeuBFK9enVj+vTpRklJibFnzx7jnnvuMaxWq7P+tm3bjO3btxvnz583CgsLjSeffNK4++67jZKSEsMwDGPjxo2G1Wo1HA6Hy7gaNmxovPHGG4ZhGMYbb7xhNG7c2KW9R48eRlJSkmEYxhXHKRW7kc/AwYMHDavVanz99dfOemXvaWlpqWEYhjF58mSjY8eOLus8ePCgYbFYjA4dOhhHjhwxHA6HUVxcfNWfl7LacvViYmIMX19fY82aNUZpaamxdu1aw9vb29i2bZvx6aefGt7e3saKFSuM0tJS4/PPPzfq1atnzJ071zAMw3j99deN1q1bG7m5uYZhGMYPP/xgZGVlGYZx6WcgNTXVqF+//iXrt1gsxr/+9S/DMAzj+eefN2JjY13aW7Zsabz88suGYRjGhg0bjMDAQGPDhg2GYRhGTk6O0aBBA2PZsmWV/8LcBAqtmygmJsYYMWKEy7yaNWsay5cvN8aNG2cMHDjQpW3p0qVG06ZNDcMwjCVLlhh169Z1aZ8/f75LaF0sNzfXsFgsRnZ2tmEY5X8J/TS0Tp8+bQQGBjo/8IcOHTKqVKli7NmzxzAM44rjlIrdyGfgRkNr3bp1FY7taj8vcmUxMTHGI4884jJvwIABxogRI4wnn3zS6N+/v0vbnDlzjBYtWhiGYRhvvfWWcc899xibN292/gOiTNl7eS2hdfDgQaNKlSrGvn37DMMwjH//+9+Gr6+vcerUKcMwDKN3797Gs88+67L8Cy+8YMTFxV3v07+lTPHjYjOrV6+ey7Sfnx8FBQXs3buXDRs2sHbtWmebw+Fw7jI4evToJQdcyw7GlvnPf/7Ds88+yxdffEFhYSEWiwWLxcKxY8do1arVVY3P19eXX//617zxxhs8+OCDLF68mAceeIB77rkHgL1797Jx40ZCQkIuO065suv9DNwIi8VyUz4vUr7GjRu7TDdq1IgvvviCqlWr0rJlS5e2pk2bcujQIQAGDRrEiRMnSEpKYvfu3bRv355p06bRunXr6xrH3XffTWxsLIsXL+aFF17gjTfeoH///thsNuDC3/S//vUvXnnlFeDCcTKHw8Hdd999Xeu71XRMy03q1q3LwIEDyc3NdT7y8/M5derCFZVDQ0M5fPiwyzIXn/YaHx9P06ZN+fLLL8nPz+fAgQMYF7aeAVyOf1Vk5MiRrFq1ipMnT5KamsqoUaOcbXXq1OGxxx4rd5xy/a70GQgICMAwDE6fPu1c5siRIy41KnqPL2670udFbsyBAwcuma5fvz7169e/5Arp+/bto0GDBsCF9+l3v/sdH3/8MUePHuXee++lT58+zr4/PfHiWv6m33rrLfLy8khLS7vkb/qZZ55xfuby8vI4deoUu3btuubn7A4KLTcZPXo0K1asYMWKFZSUlOBwOPj666/JyMgAoFevXhQXF/PnP/+ZkpISvvrqq0sOltrtdmw2GwEBAeTm5jJhwgSXD3idOnUA2L274tsZtG3blmbNmjFs2DDy8vKIj493tiUkJFQ4Trl+V/oMhISE0LhxYxYtWkRpaSn79+8nJSXFpUadOnU4dOiQ660b4LJBdKXPi9yYtWvX8o9//AOHw0F6ejqrV69m+PDhDBs2jLVr17Jq1SocDgdZWVnMmjWLJ598EoANGzbw+eefU1JSgre3N/7+/lSp8uNOsJ++l3Xq1OHEiRPk5lZ8a5R+/fpRXFzMkCFDqFu3rsvp8OPHj+ell15i/fr1lJaWUlpaSk5ODlu2bKnkV+TmUGjdRJf7Qiib16ZNG9atW8frr79OaGgoNWrUID4+3rnLIDAwkLVr1/Lee+9RvXp1Bg0axIgRI1yuXL948WKWL19OQEAA0dHR9OrVy2VdzZo1Y9y4ccTGxhISEsKLL75Y7rhGjhzJmjVreOyxx7jrrruc8680TqnYjXwGAN5++202bNhAcHAwgwcPdvkXM8CAAQNo3rw59erVIyQkhG3btpW73it9XuTGDB8+nEWLFhEUFMTYsWNZuHAh0dHRtG3blhUrVjB9+nRCQkIYMGAATz/9NOPGjQPg2LFjDB06lOrVq1O7dm02b97MihUrnHV/+l4++OCD9OnTh3vuuYeQkBDefffdS/oAVK1alccff5w1a9YwcuRIl7Y+ffqwZMkSJk2aRK1atahduzajRo3i5MmTN+ulqVS69qCJ/OUvf2HhwoX897//dfdQROQnYmNj6dixI1OnTnX3UO542tK6ja1fv55vv/0WgM8++4yUlBQGDRrk5lGJiLiPzh68je3evZvHH3+cU6dOUatWLQYPHszvf/97dw9LRC6iY4O3jnYPioiIaWj3oIiImIZCS0RETEOhJSIipqHQEhER01BoiYiIaSi0REygZ8+el9z3TMQT6ZR3kdvIN998Q6NGjdi3b98lVw13t9t5bOI5tKUlchsxbuPbqd/OYxPPodASuQ7z58+nadOmBAYGUrduXYYPHw7AqVOnGD16NA0bNqRmzZr06tXL5ZYVw4YN4ze/+Q1jx46lRo0a1K1bl0mTJjnbw8PDAbjvvvuw2WwkJCQAF65t99N+VquVefPmER0djb+/P5GRkWRnZ7NixQruvfdegoKCiI+Pp6ioyLnMzRqbyC11i286KWJ6e/fuNXx9fY0vv/zSMIwLd3/esmWLYRiGERsbazz++ONGfn6+UVxcbDzzzDNGy5YtjfPnzxuGYRhDhw41qlWrZixfvtxwOBzG9u3bjapVqxobN240DOPHuxXv37/fZZ0xMTHG888/75y2WCxG69atjW+++cYoKSkxfv3rXxtNmjQxhg8fbpw+fdo4duyY0aRJE2PGjBnOZW7W2ERuJW1piVyjsnsdZWdnU1BQgK+vLx06dCArK4tt27bx6quvEhgYSNWqVZk+fToHDhzgk08+cS7fvn174uPjsVgsPPDAA0RERPDpp5+6rMO4ikPNiYmJNGjQgCpVqjBw4EAOHDjAn//8Z3x9falZsyY9e/Z01v3iiy9u6dhEbhZdMFfkGjVs2JB3332XV155hSeeeILmzZvz9NNPY7VaKSkpISwszNnX+N9xoJ/ehbpevXou9fz8/CgoKLjmcZTd5LOsBkCtWrUuW3ffvn23dGwiN4tCS+Q6PPTQQzz00EM4HA5WrlzJo48+ysaNG/Hx8eH48eN4eXldV12r1XpTtmTq1Klz245N5Fpo96DINfrqq69IT0/n9OnTWK1WbDYbFouFsLAwwsPDeeqppzh+/DgAeXl5vPfee5w9e/aqatesWRMvLy/27NlTqWPu0KHDbTs2kWuh0BK5RsXFxUyfPp2wsDCCgoJISkpiyZIlNGrUiHXr1uHr60u7du0IDAwkMjKS999/v8JTxX/aVq1aNf70pz8xYsQIQkJCGDNmzCV9Ljd9JVar9aaNTeRW0o+LRUTENLSlJSIipqHQEhER01BoiYiIaSi0RETENBRaIiJiGgotERExDYWWiIiYxv8H5Y9Yy4KcpRIAAAAASUVORK5CYII=\" class=\"pd_save\"></center>\n",
       "                        \n",
       "                    \n",
       "                \n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "import pixiedust\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# The schema is created for the DataFrame\n",
    "names = ['scoreName','score','summary','text','sentiment']\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in names]\n",
    "schema = StructType(fields)\n",
    "\n",
    "# The dataframe is launched according to the schema created above\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "reviews_DF = spark.createDataFrame(reviews_RDD_filtered,schema)\n",
    "reviews_DF.createOrReplaceTempView(\"reviews\") \n",
    "\n",
    "# Show a bite of the DataFrame\n",
    "reviews_DF.printSchema() # print the schema\n",
    "SQL1 = \"SELECT scoreName,score,summary,text,sentiment FROM reviews\"\n",
    "reviews_sql = spark.sql(SQL1)\n",
    "reviews_sql.show(5)\n",
    "\n",
    "# Visualize scores with pixidust\n",
    "display(reviews_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Text Processing Pipeline\n",
    "\n",
    "In order to conduct different experiments with the dataframe, we create a text processing pipeline. Text data needs to be transformed into a set of numerical features for the analysis. In this project, we are using TF-IDF transformation, which accounts for a numerical value per word per document that weights the frequency and uniqueness of each word on each document. Then, hashing trick is used to reduce the dimensionality of the problem. Before transforming the words, they are tokenized and stopwords are removed to simplify the task.\n",
    "\n",
    "Once we have a set of numerical features, the model fits the data and it is evaluated. To find the best combination of parameters, different scenarios are tested along the pipeline. Grid searching different combinations allow us to navigate the model to the optimal solution. \n",
    "\n",
    "Accuracy is used as the evaluation metric to measure how well the model is performing. To avoid overfitting, the accuracy is calculated in validation set. Cross-validation is the best vehicle to estimate the generalization performance, but the size of the dataset raises the computational cost of the task. Therefor in this project, we are using the TrainValidationSplit function in pyspark.ml.tuning package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import HashingTF,StopWordsRemover,IDF,Tokenizer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "def setPipeline(model,inputCol):\n",
    "\n",
    "    # Each message is broken into words with the predetermined Tokenizer \n",
    "    tokenizer = Tokenizer().setInputCol(inputCol).setOutputCol(\"words\")\n",
    "    \n",
    "    # Stopwords are removed\n",
    "    remover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filteredWords\").setCaseSensitive(False)\n",
    "    \n",
    "    # Now the TF hashing trick is applied on the words of the text\n",
    "    hashingTF = HashingTF().setNumFeatures(1000).setInputCol(\"filteredWords\").setOutputCol(\"rawFeatures\")\n",
    "    \n",
    "    # Now, idf is used to rescale the features\n",
    "    idf = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(0)\n",
    "    \n",
    "    # Pipeline is assemblied here\n",
    "    grid = ParamGridBuilder().addGrid(hashingTF.numFeatures,[100,1000,10000]).addGrid(idf.minDocFreq,[0,10,100])\n",
    "    pipeline = Pipeline(stages=[tokenizer,remover,hashingTF,idf,model]) \n",
    "    return (pipeline,grid)\n",
    "    \n",
    "    \n",
    "def trainPipeline(pipeline,evaluator,data,grid): \n",
    "    \n",
    "    # The validator is built up\n",
    "    validator = TrainValidationSplit().setEstimator(pipeline).setEvaluator(evaluator)\\\n",
    "                                      .setEstimatorParamMaps(grid).setTrainRatio(0.8)\n",
    "        \n",
    "    # Finally train the pipeline and returns\n",
    "    return validator.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) PCA analysis\n",
    "\n",
    "The first step is to perform a PCA analysis on the dataset and check whether we are able to see any pattern on the data. Sentiment labels are used to see if any group or cluster appears and what kind of structures can the data show. In this case, dimensionality reduction allows us to bring high dimensional data into two dimensions just for the purpose of the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA input: \n",
      "\n",
      "+---------+-----+--------------------+--------------------+---------+\n",
      "|scoreName|score|             summary|                text|sentiment|\n",
      "+---------+-----+--------------------+--------------------+---------+\n",
      "|     five|    5|Good Quality Dog ...|I have bought sev...| positive|\n",
      "+---------+-----+--------------------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "PCA output: \n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|       filteredWords|         rawFeatures|            features|         pcaFeatures|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Product arrived l...|[product, arrived...|[product, arrived...|(1000,[121,127,17...|(1000,[121,127,17...|[-1.7068213371761...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "# Instantiate PCA model\n",
    "pca = PCA(k=2, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "\n",
    "# Obtain the pipeline\n",
    "pipeline,grid = setPipeline(pca,\"text\")\n",
    "\n",
    "# And finally the analysis is performed\n",
    "model = pipeline.fit(reviews_DF.select('text'))\n",
    "transformed_pca = model.transform(reviews_DF.select('text'))\n",
    "\n",
    "# Print some checkvalues\n",
    "print(\"PCA input: \\n\")\n",
    "reviews_DF.show(1)\n",
    "print(\"PCA output: \\n\")\n",
    "transformed_pca.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "chartsize": "50",
      "clusterby": "sentiment",
      "handlerId": "scatterPlot",
      "keyFields": "pca1",
      "kind": "scatter",
      "mpld3": "false",
      "rendererId": "seaborn",
      "rowCount": "10000",
      "valueFields": "pca2"
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>\n",
       "        <div class=\"pd_save is-viewer-good\" style=\"padding-right:10px;text-align: center;line-height:initial !important;font-size: xx-large;font-weight: 500;color: coral;\">\n",
       "            \n",
       "        </div>\n",
       "    <div id=\"chartFigurec651ecd9\" class=\"pd_save is-viewer-good\" style=\"overflow-x:auto\">\n",
       "            \n",
       "                    \n",
       "                            <center><img style=\"max-width:initial !important\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAjMAAAIsCAYAAAAH0iiMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAOwwAADsMBx2+oZAAAIABJREFUeJzs3Xl8VPW9//H3TBaSAUJCgiyCCGKxJawWaLEqRTZxv23UNj/lotddUQgoKpvAbSsatSi1Wq9XxOUW6q0LVbBqFYtLqVfAoNKCCKggCdkgk4SEnN8fp5NkklnDzJxzktfz8ZgHztnmM5PIvPku5+syDMMQAACAQ7mtLgAAAOB4EGYAAICjEWYAAICjEWYAAICjEWYAAICjEWYAAICjEWYAAICjEWYAAICjJVtdAACg4/J6vaqtrQ24r1OnTvJ4PAmuCE5EmAEAWMLr9eqxx36vkpK6gPtzclJ03XWXEWgQFmEGAGCJ2tpalZTUqXPnyUpP7+a3r7q6QiUlr6u2tpYwg7AIMwAAS6Wnd1PnzlmttldVWVAMHIkBwAAAwNFomQEA2FJd3VGVl5e32s7AYLREmAEA2M7Ro1793/9t0yOPHFNaWrrfPgYGoyXCDADAdurrj6q62i2PZ5K6d+/duJ2BwQiEMAMAsK20tIxWg4MZGIyWGAAMAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcjTADAAAcLdnqAgAA7Z/X61Vtba3ftvLyctXVHbWoIrQnhBkAQFx5vV499tjvVVJS57e9urpK27bt1OTJtUHOBCJDmAEAxFVtba1KSurUufNkpad3a9xeWrpX1dU7VFdXb2F1aA8IMwCAhEhP76bOnbMan3u95RZWg/aEAcAAAMDRCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRWGgSABAzXq9XtbW1ftvKy8tVV3fUoorQERBmAAAx4fV69dhjv1dJSZ3f9urqKm3btlOTJ9cGORM4PoQZAEBM1NbWqqSkTp07T1Z6erfG7aWle1VdvUN1dfUWVof2jDADAIip9PRu6tw5q/G511tuYTXoCBgADAAAHI0wAwAAHI0wAwAAHI0wAwAAHI0BwACAqAS6l4zE/WRgHcIMACBiwe4lI3E/GViHMAMAiFiwe8lI3E8G1iHMAACi1vJeMhL3k4F1GAAMAAAcjTADAAAcjW4mAEBArIANpyDMAABaYQVsOAlhBgDQCitgw0kIMwDQgYW7AR4rYMMJCDMA0EFxAzy0F8xmspm1a9daXUK7wWcZO3yWsWPVZ+n1elVWVub3+Pbbb7V/f5U6d56snJw8v0fnzhNUXX3M1t1J/F7Ch5YZm1m7dq3y8vKsLqNd4LOMHT7L2InnZxmsy8jr9eqZZ9apstLlt72p9eWnjrwBHr+X8CHMAIBNBQsnx44dU1JSUqtjAwUWqSm0nHnmTGVknNC4ncG8aC8IMwAQI8HCh9QUQI4ePaqysrJW2wNdK1A4qas7qh07ijR4cK5SUlIbtwcLLFJTaElO7sxgXrRLHSLM1NTUaNeuXVaXEZHKykpt37496P6GhgZt3bpVhw8fbrWvR48eGjBgQNC/TDuaQ4cO6b333rO6jHaBzzK8mpoarVv3jo4cad0yUl9fp927/6kBA07Vtm3/1B13/LrV9uTklBbXq9Y//rFXubkXy+Npmhp9+HCx9u4tVffu2eraNctv+6FD72v//h3yeg/5XauiYr+83lLt2/d/qqzcG3Z7os5py7Vqao6ouvobffbZZ2H/vrSLU045RWlpaVaX0a65DMMwrC4i3rZv367c3FyrywAAdEBFRUUaMmSI1WW0ax0izDipZQYA0L7QMhN/HSLMAACA9ov7zAAAAEcjzAAAAEcjzAAAAEcjzAAAAEcjzAAAAEcjzAAAAEezZZhZsmSJBg0apMzMTJ1wwgk699xztXXrVr9jtm3bprPPPltdunRR3759dc8991hULQAAsJItw8zPfvYzffTRRyovL9c333yjSZMmacqUKfLdEufIkSOaOnWqzjzzTJWWlmr9+vV64okn9Otf/9riygEAQKLZMsyceuqp6tbNXIvk2LFjcrvdKi4uVmlpqSTphRdeUENDg5YsWaLU1FTl5uZq7ty5euSRR6wsGwAAWMC2C02++uqrys/PV0VFhdxut2bPnq3s7GxJ0tatWzVy5Ei53U1ZbPTo0friiy905MgRdenSxaqyAQBAgtk2zEybNk1lZWUqLy/XqlWr1Ldv38Z9lZWVyszM9Ds+KyurcR9hBgCAjsOW3UzNZWZmaubMmbr66qv1ySefSJIyMjJUXl7ud1xZWVnjvpZqamq0fft21dTUxL9gAACOA99Z0bNty0xzx44dU11dnf75z39q6NChGjFihJ577jk1NDQ0djVt3rxZAwcODNgqs2vXLuXm5mrKlCl+YScvL095eXkJex8AAITDd1b0bBlmVqxYocsvv1wnnHCCiouLdffdd6tTp04644wzJEn/9m//pjvvvFOLFi3S3XffrZ07d6qwsFCzZ88Oed3CwkINGTIkEW8BAIDjwndW5GzZzfTnP/9Zw4cPV9euXTVixAgdPHhQb7zxhnr27ClJ6tKlizZs2KB33nlH2dnZmjx5sv7jP/5Dt956q8WVAwCARLNly8wrr7wS9pjc3Fxt3LgxAdUAAAA7s2XLDAAAQKQIMwAAwNEIMwAAwNFsOWYGHds333zTeN8gALCzrKws9enTx+oyOjzCDGzlm2++0WmnnabDhw9bXQoAhNW1a1d9/vnnBBqLEWZgK2VlZTp8+LBefPFFDRo0yOpyACConTt36uKLL1ZZWRlhxmKEGdjSoEGDuFkUACAiDAAGAACORpgBAACORpgBAACORpgB0CHV1tZq7ty56tOnjzwej8aNG6d33303onOffvpp/fSnP9XJJ58st9utq666KuBxmzZt0owZMzR06FClpKRo4MCBsXwLlnnnnXfkdruDPv72t79FfK2Kigr16tVLbrdbb731VsxqPHDggO68806NHj1amZmZOuGEEzRx4sRWP+M9e/aEfC9r1qyJWU2IHwYAA+iQrrrqKr322mu6//77NWDAAD3yyCOaMmWKPvjgAw0bNizkuc8884xKSko0efJkrV27Nuhxb775pv7617/q+9//vtxud7u55cDpp5+uDz74oNX2q666SmVlZRo9enTE17r99tuVlJQkl8sVyxL10Ucfae3atbrqqqs0duxYHT16VL/5zW80fvx4vfLKK5o2bZokqXfv3gHfy913361NmzZp8uTJMa0LcWJ0AEVFRYYko6ioyOpSEAY/q/iqra21uoRGVtayZcsWw+VyGatWrWrcVl9fbwwePNi46KKLorpW3759jRkzZoQ97v/9v/9nDBgwIOpanWLPnj2G2+027rjjjojP+etf/2p06dLF+O///m/D5XIZb775ZszqqaioMI4dO+a3zfczPvvss0Oe6/V6jYyMDOOyyy4LeVy8/r7i78Ho0c0ExNnixYvldrtVVFSkCRMmqHPnzurTp48WLVrU6thDhw7phhtuUN++fZWWlqbvfve7+t3vfud3TElJia6//noNHjxYnTt31kknnaT8/Hx98803AV93+/btmjp1qrp27arLLrtMkrRhwwadccYZyszMVNeuXXXaaadp2bJlfuevX79e48aNk8fjUWZmpi655BL94x//8Dtm/PjxOvPMM/Xmm2/q9NNPV+fOnTV06FC99NJLEddihZdfflmpqam69NJLG7clJSXp8ssv14YNG1RXV2dZbeG43W7Nnz9fv/jFL9SvXz95PB6dffbZ2rp1q6V1Pf3005KkK6+8MqLj6+vrdf311+vOO+/UgAEDgh73zjvvaOLEicrIyFCXLl00depUbd++Pez1MzIy5Hb7f8UlJSVpxIgR+vrrr0Oe+8ILL+jIkSOaPn16RO8F1iPMAHHmaz6/5JJLNGnSJL300kvKz8/X0qVLtWTJksbjDh8+rHHjxum1117TkiVL9Oqrr+rCCy/UDTfcoJUrVzYeV1paqvT0dN17773asGGD7r//fu3cuVM/+tGPdPTo0Vave/HFFzc2rc+aNUu7d+/WRRddpFNOOUVr1qzRK6+8ooKCAlVVVTWeu379ep1//vnKyMjQ2rVr9dvf/lZFRUU688wztX//fr/X2LVrl2677TbNmTNHf/zjH9W7d2/l5eXpiy++CFtLKMeOHQv7MAyjLT8SffrppxowYIDS0tL8tg8ZMkRHjx7Vzp0723TdtvKN22j++xDK008/rddee00rV67UqlWr9O2332rixIkqLy8Pe268PtfVq1dr1KhR+t73vhfR8ffee6/q6uo0d+7coMf86U9/agwyzz77rJ5//nkdPnxYZ555ZthAEkhdXZ3ef//9sDWuWrVKJ5xwgqZMmRL1a8AiVjcNJQJNds7RHn9WixcvNtxut7F8+XK/7ddcc42RkZFhVFRUGIZhGEuWLDHS09ONXbt2tTquR48erZrMfY4dO2bs27fPcLlcxosvvtjqdR9++GG/4//whz8YbrfbOHz4cNCaTz/9dOM73/mO32vu3r3bSElJMQoKChq3jR8/3khNTfWr+eDBg0ZSUpLxy1/+MmwtwTz11FOGy+UK+4ikeyeQyZMnGz/84Q9bbX/jjTcMt9tt/PWvf434WrHoZtqzZ4+RkpJiLFu2LOx1XC6X0aNHD6O6urpx25dffmmkpKQYCxcuDHluvD7X9957z3C5XMYjjzwS0fH//Oc/jfT09MZupbfffjtgN9OgQYOMSZMm+W07fPiwkZOTY8yaNSuqGg3DMO68804jKSnJ2LRpU9Bjvv76ayMpKcmYM2dO2OvRzWQfDAAGEiQvL8/v+eWXX67/+q//UlFRkcaNG6cNGzZo7Nix6t+/v44dO9Z43OTJk/Vf//Vf+vTTT5WbmytJevTRR/XYY49p165djS0qLpdLO3bsaPW6F198sd/zESNGKCUlRZdddpmuuuoqnXXWWerRo0fjfq/Xq48//lh33323XzP9ySefrDPOOEPvvPOO3/VOPfVUv1k6PXr00AknnKC9e/eGrSWYCy+8UH//+9/DHpeTkxNyf0NDg18rg9vtlsvlkmEYAQecGm1s6TleJ510kl+rWjjTpk3za1Xq37+/fvCDH+j9998PeV6sPteWVq1apdTUVP3sZz+L6Pgbb7xRl1xyiSZMmBD0mJ07d2rXrl26++67/f5/SEtL0w9/+ENt3LhRkvkza2hoaNzvcrladS9J0nPPPad7771XixYt0rhx44K+7tNPPy3DMCLuLoM9EGaABOnZs2er54ZhNDaXHzx4ULt27VJKSkqrc10ulw4dOiRJevjhh3Xrrbdqzpw5mjx5srKystTQ0KCxY8eqpqam1bm9e/f2e37KKadow4YNuvfee3XllVeqpqZGo0eP1vLly3XWWWeprKxMhmG0Ok+SevXq1Wrabffu3Vsd16lTp4hqCSYrK0sZGRlhjwv0pdXcOeec0xi+XC6XFi1apIULF6p79+7at29fq+N9q7UHek920vJ3ybft008/DXlerD7X5o4ePaq1a9fq/PPPj+hzW7NmjTZt2qSPPvpIFRUVkswuVpfLpaqqKlVWViojI0MHDx6UJF199dWtpr67XC71799fkrRkyRLdc889jfvGjx/faor3K6+8ohkzZuiaa67RwoULQ9a3evVqjRgxQkOHDg3/5mEbhBkgQb799ludfPLJfs8lqW/fvpKk7Oxs9ezZUytWrAjYQjB48GBJ0u9//3tNnDhRy5cvb9z35ZdfBn3dQC0QZ599ts4++2zV1dVp06ZNWrBggc4//3x9+eWXysrKksvl0oEDB1qdd+DAAWVnZ0f0fiOtJZBVq1ZpxowZYY/793//dz355JNB9z/++ON+06F9iwEOGTJEL774ompqavxaOLZv367U1FTbL3Lq+91pue3EE08MeV6sPtfmXnrpJZWXl0c8WPazzz5TTU1Nq3ErLpdLF110kTIzM1VaWtr4e/bLX/5SEydObHWd1NRUSdJ1112nCy64oHF7165d/Y578803demll+onP/mJfvvb34asbfPmzfrss8/061//OqL3AvsgzAAJsmbNGt1+++2Nz59//nl17dq1cUHNqVOn6pFHHlG/fv1CNvN7vV5169bNb9uTTz7Zpvt0pKSkaPz48br99tt18cUXa/fu3Tr99NN1+umna+3atVq8eHHjdffs2aP33ntPt956a9SvE61YdYeceuqpQa+/aNEirV27VldccYUkc2DsmjVrNGXKlICtY3by6quvqrq6Wunp6ZLMMPvBBx/orrvuCnlePLqZVq1apezs7Mb7toQzY8YM/fjHP/bb9vHHH2v27Nl64IEHNGbMGElmeD/55JO1fft2v/9vWurVq5d69eoVcN/777+viy++WJMmTdLq1asjei8pKSkRd5fBPggzQAIYhqHf/e53OnbsmEaPHq3169frySef1D333NPY7D9r1iytWbNGP/rRjzRr1iwNHjxYVVVV+vzzz/Xuu+/qxRdflGSGnuXLl+uXv/ylxowZo7feekt/+MMfIq7lscce08aNGzVt2jT169dPxcXF+tWvfqUTTzyxcUzO0qVLdf755+u8887TjTfeqMOHD2vx4sXKysrS7NmzY/8BtZCVlaWsrKy4XX/48OG67LLLdNttt+no0aMaMGCAfvOb3+jLL7/U888/73fsoEGDNGDAAP35z39u3PbZZ5/p008/lWEYqq6u1p49e/TCCy9IMlu9fGGgpKSksZtr79698nq9jcd973vf03e/+11JZlAcMGCAFi9eHLYbRJLS09M1efJkzZkzRzU1NVq0aJEyMzN12223hTwv1p/rwYMH9frrr+umm25SUlJSwGOuvvpqPf30043T3U866SSddNJJfscYhiHDMDRs2DC/8SwrV67UxRdfrNraWl166aXKycnRt99+q/fee0/9+/cP+X537Nih8847Tz169FBBQUGrEDd27Fi/5/X19fr973+vadOmRT1mCNYjzAAJ4HK59NJLL+nmm2/WsmXL1K1bNy1YsEDz589vPCYjI0PvvfeelixZouXLl+vrr79WZmamBg8erJ/85CeNxy1cuFAVFRV66KGHVFNTo/Hjx+v111/XwIEDW7XOBGqtGT58uNavX6+77rpLBw8eVPfu3XXmmWfqueeeU6dOnSRJU6ZM0Z/+9Cfdc889uuyyy5Samqof//jHuvfee1v9KzjQa7hcrohqsdJTTz2lu+++WwsWLFB5ebmGDx+uDRs2aPjw4X7HNTQ0+A0wlcxWtubTqN9++229/fbbkqS//OUvOuussySZ3VZ5eXl+7913bxvf+B1JjYO4Ix1TdOWVV6pz5866+eabdejQIY0ZM0Zr165VZmZmFJ/A8Xvuued07NixkINlWw7CDibQ78e5556rjRs36j//8z91zTXXqLq6Wr169dIPfvADXX755SGv98EHH6iiokIVFRUBBxo3H1QsSevWrVNpaSn3lnEol2HV8P0E2r59u3Jzc1VUVNTYpA97ao8/q3vuuUdLlixRXV1dVAMr0XE8/vjjWrBggfbs2dPq3jct+W6aF+k9aRA/8fr7qj3+PRhv/M0KABbbuHGjZs+eHTbIAAiMbiYgAezWxQJ7eeaZZyI+NlAXHtDREWaAOFu0aFHAdZiAtmg51gMA3UwAAMDhCDMAAMDRCDMAAMDRCDMAAMDRCDMAAMDRmM0EW9q5c6fVJQBASPw9ZR+EGdhKVlaWunbtqosvvtjqUgAgrK5du8Z1HTFEhjADW+nTp48+//xzlZWVWV0KAISVlZWlPn36WF1Gh0eYge306dOHvxwAABFjADAAAHA0wgwAAHA0W4aZO++8U8OGDVO3bt104okn6uc//7m++uorv2P27dunCy64QBkZGTrhhBN0yy23qL6+3qKKAQCAVWwZZtxut1atWqVDhw7ps88+k8vl0gUXXNC43zAMnXfeecrJydH+/fv10UcfaePGjZo7d66FVQMAACu4DMMwrC4inK1bt2rUqFEqLS1Vt27d9M4772jy5Mk6cOBA45S4l19+Wfn5+SotLVVKSorf+du3b1dubq6Kioo0ZMgQK94CAAAR4TsrerZsmWlpw4YN6t+/v7p16ybJDDcDBw70m9s/evRoVVVVaceOHVaVCQAALGD7qdlvvPGGli5dqv/93/9t3FZZWanMzEy/43zBprKyMqH1AQAAa9m6ZWbdunXKy8vTs88+q0mTJjVuz8jIUHl5ud+xvpusZWRkJLRGAABgLdu2zDz77LO6+eabtXbtWk2cONFv34gRI7R7926VlZU1tshs3rxZnTt31ne+852g1ywoKPALO3l5ecrLy4vPGwAA4DjwnRU5Ww4AfuSRR7RgwQKtW7dOZ5xxRqv9hmFo5MiRGjVqlFasWKHS0lJddNFFGj9+vB588MFWxzOYCgDgFHxnRc+W3UwzZ86U1+vVueeeq4yMDHXt2lUZGRnatGmTJMnlcumVV17RwYMH1bt3b51++uk666yztHz5cosrBwAAiWbLbqaGhoawx/Tr10/r1q1LQDUAAMDObNkyAwAAECnCDAAAcDTCDBxr1SppxAjzTwBAx0WYgeMUFUkul/Tv/y5t3Wr+6XKZ2wEAHQ9hBo4zdGh02wEA7RthBo4SrkuJLicA6HgIM3CUAPdE9LNiRWLqAIB4q6mpsboExyDMwFFmzQq9f+bMxNQBAPFWW1trdQmOQZiBo0yffnz7AQDtD2EGjvPJJ9FtBwC0b4QZOE5urmQY0lNPSaNGmX8ahrkdANDx2HJtJiAS06fTrQQAoGUGAAA4HGEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4GmEGAAA4mi3DzO9//3udddZZ6tatm5KSktTQ0OC3f9u2bTr77LPVpUsX9e3bV/fcc49FlQIAAKvZMsx0795dN910kx566KFW+44cOaKpU6fqzDPPVGlpqdavX68nnnhCv/71ry2oFAAAWM2WYWbSpEm67LLLNHDgwFb7XnjhBTU0NGjJkiVKTU1Vbm6u5s6dq0ceecSCSgEAgNVsGWZC2bp1q0aOHCm3u6n00aNH64svvtCRI0csrAwAAFjBcWGmsrJSmZmZftuysrIa9wEAgI4l2eoCopWRkaGvv/7ab1tZWVnjvlAKCgr8jsnLy1NeXl7siwQA4DgtWLBA2dnZjc/5zgrOcWFmxIgReu6559TQ0NDY1bR582YNHDhQXbp0CXluYWGhhgwZkogyAQA4LkuXLtW4ceOsLsMRbNnN1NDQoNraWtXW1kqSampqVFtbK8Mw9G//9m9KSkrSokWLVFNTo6KiIhUWFurmm2+2uGoAAGAFW4aZ1atXKz09Xeeee64kqUuXLvJ4PHr33XfVpUsXbdiwQe+8846ys7M1efJk/cd//IduvfVWi6sGAABWsGU30/Tp0zV9+vSg+3Nzc7Vx48YEVgQAAOzKli0zAAAAkSLMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAP/i9Uq7dpl/AgCcgzCDDq++Xpo3T8rJkQYNMv+cN8/cjtghLAKIF8IMOrz586X77pOqq83n1dXm8/nzra2rvSAsAog3wgw6NK9XWrFCamjw397QID38cMdsRYh1CwphEUC8EWbQoe3f3/Ql25LXKx04kNh6rBSPFhTCIoBEIMygQ+vdW0pPD7zP45F69UpsPVaKRwsKYRFAIhBm0KF5PNLMmZK7xf8Jbrd0yy3m/o4gXi0ohEUAiUCYQYe3bJk0d25TcPF4zOfLlllbVyLFqwWFsAggEQgz6PCSk6Vf/UoqLjYHvhYXm8+TkxNXQzynLUdy7Xi2oBAWAcQbYQb4F49HGjgwsa0F8Zy2HM2149mCYoewCKB9468TwEK+Qbe+sSq+QbeS+YWfyGv7Wkp8Y2Q8HjPIxKoFxRcWASDWXIZhGFYXEW/bt29Xbm6uioqKNGTIEKvLASSZgSEnJ/BYFY/HbMFoa4vI8VzbN0amVy/GtABW8H1nbdq0SePGjbO6HEegmwmwSDynLR/Pta3obgOA40GYASwSz0G3TImOHmtHAc5FmAEsEs9Bt+15SnSsQ0ekA6Wjed3jqZFQBUSPMANYKJ7TltvblOhoZ35FGgrC3fk4mtcNd2yomqJ5HQIP0ILRARQVFRmSjKKiIqtLAQKqqjKMXbsMo7jYMHbuNJ/H+tqxvKYV7rjDMNxuw5CaHm63ub25ujpzW1qaeUxamvm8rq71NauqDCM93f+avofHY+6P9HWD1ehyGcbcueY+32ulp/vXVFVlGNddF/51fO8t2HXQPvi+s958802rS3EMwgxgA3xJhRZJ6PCZOzfwcXPntr7uzp2Bj/U9Xn018tcNVaMvmLR87gs5vuAV7nWiCVZwLt931qxZC40qp/8rJEHoZgJsIB6LPLYnkc7O8nqlBx4IfNyDD7bulgk1UFqSpk2LfFZYqBqlwOtePfig+XOuqQl+nu91WIG84zlyxKXa2lqry3AEwgxgMb6kwot0dtYXX0jHjgU+rr5e2r279bmBBkpHouWssN69pbS06K5RX9/65x7sdViBHAiOMANYjC+p8OI5O2vxYmn06OjOcbul6683f3a+sOnxSD//edvrCPY6vvfHdHsgOMIMkECBZqHwJRWZSGZnDRwYfM2npCRzlEnLlq7Fi6XNmyOvIz3dDD+PPtp61tEtt0T1lsIaPbrp/fkCncvV+rihQ83XZ4YTOirCDJAAoabdtud7wsTL3+sNAAAgAElEQVRSJAtWejzSqFGBzz92zPzSz8qSCgrMzz5YF18wP/mJNH68GX4CjW/6znfM0BROpN1an3wiHT3a9HzZssCtSB9+KGVnm79b2dnS1VdLW7Y0BZtwU7mb74902jfTw2ErVo9ATgRmM8Fq4Wah+GYzeTxNM1iYzRS9qqrQM4OaP0aPNozPP4/s2EgeHo9hVFQYxpgxsbumZE6rb/7+kpMjPzcpyawn2Cy5lrPo3O6m66elGca11xrG/v3+twuoqzOMgoKmz5mZd7Hn+86aMeMuo7S01OpyHIGFJoE4i2bRx466yKPXa44/6d37+N73rl1m60SkZs6UHn889GyiaFx3nfTYY7G5lmR+Fnv2NI2bqq6Wxow5vmu63dJtt0k33mh2lT3wgBl9wklLM8cJ/eUv0tat/vtcLun224Ov9B6rn29H4fvOGj8+T2vX/kY5OTlWl2R7dDMBcRbNAN/2tMhjJN0Q0d7VN5xwU61bevxxKT+/ba/VUqdO0qpVsblW82v26mV2jw0devxBRjK71B54wPy8CwsjCzKSGfgeeqh1kJHMa9x3nzmbbNcuqaTE7Ipbt84MTb4usOP9+XY0AwacqqRI+i1BmAHiraMN8I0moMT6/jq+8UeRqqkxxyUFGzQcjdra2LXw+JSVBZ9qbjcNDdIpp5g/8x49zOB1wQVm64/vc/H9fO+4g/E2kUhOTrG6BMcgzABx1tEG+EYaUOJ1f53bbw884yeQtDTpySdpKUik5i1DmZnS9On+g5WBtiDMAAnQ3hZ9DCZUQFmxwv8L63jvrxOsG+vOOyPvOuna1awL1qirk55+Who5UurcWfrZz6Q//EF6912pqIiAg8jFoHEVQDi+acULF8Z+gK+dBleGCijV1dLs2dIjj5ifR7duZstIoK6Zlt1vzd9jaqrZyrNihXnN9HSz5WvZMnMaczTjVoqLo3t/iK//+R/z0dwZZ5iDqtPS7PE7nki1tTUqLy+3ugzLdOrUSZ4If+CODjOLFi3SE088ocrKSp1++ulauXIls5Vga74BvrFQXx/8Sz0WY0Daondv87WDddv87ndSRobZxbZiReAg07z7LdB7HDbMHFzqa/3xdWNJ0jXXmGNX0H5s2iTl5jY9v/JKsxsyI8O6mhJlx46devTRPyklJdXqUiyRk5Oi6667LKJA49gwc9999+mpp57Sn//8Z51yyim65557NGXKFP3jH/+IOMkBTuYbmxLoSz3YFNlECNXF4xsv0dAQ+DiPxwwyvu63QO/xww8DX/fhh82ZM7E2enR0dwhGfD39tPk45xxp/XrrgnsijBp1pXr3PtPqMixRXV2hkpLXVVtb277DzKOPPqq5c+fqe9/7niRp6dKleuKJJ/THP/5R+bGaawmEYGX3TrjBswsXWtMcH2qhR59g+5OSpP/7P+nrr6XycrP+aO7O6xtDE2uffBL7a+L4vfmmlJIiffyxNGKE1dXER9euOercOcvqMixTVRX5sY4cAFxZWakvv/xSo5vd1zspKUkjR47Uxx9/bGFl6AhifW+Utgg3eParrxJXi9T0mUS7YGNzx45Jp51m/ou7Rw9p3Ljg7zGQ9HTzXizR3GcmErGebo3YGjnS6gpgB44NM5KUmZnptz0rK6txHxAvsb43SluEuznc448nrhap6TOJ5Rd/oJuzhVJXJ91/v3TzzZFPzUb7kOjfd9iPI8NMxr9GfrUc5V1WVta4L5CCggJdeumljY+1a9fGtU60P/G4N0pbFuzzeKQbbgi+/9FHzbuwRnvdttQS6WKNHo85mykWNzQdO7b1WIn6emn5cjPU3H575Is5wvna6/T6l15aoMcfv7Tx8dFHfGcF48gxMxkZGTr55JO1efNmjR07VpJ07NgxbdmyRVdeeWXQ8woLC5nthOMSyb1RIp2tdLyzka691hxMG6yWfv3MlpJIrns8tYT6TCRz8Gz37k3T0ZOSmgYqt0VysvTii+bn3LJrzzDMW+7PnCl9/rk0eHDk95yBc0Vz12cnGT/+VvXr17QMfEpKsqqqyiysKHGqqyuiOt6RYUaSbrzxRt1///368Y9/rIEDB2rZsmVKTU3VJZdcYnVpaEe8XnNQq2R+efq6d4ItGhnN0gTHOxupX7/gtUitbyEf6rrHU0u4z+R73/MfjPyLX0gbNwaelRSJ+nrps89CB6gVK8z72RBkOoZrr7W6gvj48MNn9MknrzY+T09P0qhR3+0wU7VzclLUqVOniI51bJiZM2eOjhw5ookTJ+rw4cP6/ve/r/Xr1zMtGzFRXy/ddZfZ8uGbfZOcLM2aZY7JKCz071aJdmmCWMxG8i2T0DyEBBPqusdbS7A6fJ+JZHZd+WZ9lZebt69vq/R0qUuX0EHOVz/av/Y852Ps2MsaW2ZqaipVVfWWbrjhvFbjRdurDnPTvMWLF2vx4sVWl4F2yNdS0Vx9vTnAdM4ccykC3xiZlvdGiUSsuqt8r+mrJdgddUNdNxa1tKzD45FuuskMFDk55vXT0qThw80gczw3tqurMxcxZEwM3nij/U7LlqRu3XqrR48BkqSqqjI1NHRWZmamsrI67nTtYPjrAGjB65V+/evA+wyjqbWiuNhscSguNrtiorl5V6xW0vYtk+CrZd++6K8bi1pa1lFcbIaNwsKmoFRTY3YtHU+QcbmaxsnQ8tJx3X23+f/iOedYXQnsgjADtLB/f+gpxjU15qyc1FSzxaItPZuxXknbt0xCTk70141lLc2Xa4jmhnfNBZtWnZzMGJiOIj3dHDTet6/005+ad/wtLjZ//obR/hZoxfFzdDcTEA+9e4furpHMNYYyM49v2YBAXTPRdlfF6rqxriXcDKdAfCGmZWBJTpauuop7ibQHfftK995rDuDu0cO8i+/rr5v/r6WlmctR3Htv+16iIBo1NUcaZy9FO7uno3EZRvv/t8727duVm5uroqIipmYjIvPmmX+phuLxmP9aPN4x575xKbFcSbut1y0pMW/fP3So2cpzPK/tGysTTqdO5tiHyZMDH5+eLu3dK510UuD9ycnmo3n49H0ZJvKuzIG43fbsDhs0SBo1SlqzJrLjc3PNuzO/9JI5Zik5WZoyxQz0//M/rZeoSEszF/28+mrp8GHpyBHp+98P/DsVr99/J/N9Z82Ycbd69z6pcXs0Cy92NORf2JaVax8tW9a0KGKwtYSiva9MMLFcSbut1431CtyRzrRyu6XbbjN/xsGCT3W1VFkZfMZUQYE5hunAAXMl5crKpnE+u3ebSyxE20rUUlqa2XIU7XW2bTPPGTfODAFWc7vNx86d5pIXY8ead1oO1gr5s5+ZvxO+EBIoeDz+uPk5S1LPnk2ff6T/z8br9789uOyyMzVmzJjG59HM7ulwjA6gqKjIkGQUFRVZXQoiUFdnGHfcYRjp6WYPeXq6+byuLvG1FBcbRqdOvp56/4fHYxhVVYmvKR7uuMMw3G7/9+d2m9vbyvdz9Hiafo5jxzY993iafq5VVU0/72Cfc8vrNT8/2vfW/NpjxxqGyxV4v+9x3XXmdUIdE+r34/LLozs32OO73236ffR4DGP06ODvrfnP8dprDeOaawL/jGfPNowdOwyjoKDps01LM7db8f8cmr6zNm3aZHUpjkGYge3E44u1PdUTa5EEieO9/q5dTddp+dwn0s852PnBBApBvi9wX0iaPTt4GEhONoyKivDHhap7//7jDzLp6Wa9zd9/y/eWlBT8/GD7mofFggIzyPheL5p/RFRVGcbOne0n4FuJMBM9wgxsJd5frG3R1hYBOwn1RbNzZ+gv0V27ElNjvD/ncCGooKB1mHK5WoepWbOCh55QdY8dG1lrzsyZkdXR8r0VFTUFkWgfu3YFD5OzZ4cOKRUVhnH11U0tRla2pLYXhJnoEWZgK3b5Yg0k2hYBO4iky85uAdKqz7llmArW1RLsM62oCF13dXXoQONrzamuNowxY1rvmzMndED4/PO2BRmPx+xODfY70LxlyPc+d+40/5w7N/CxLcNX8zDt++/iYsP45BPz0fIz6+itPISZ6BFmYCt2+2J1uki7btp7V1qkoulqiSR0BfpSLi42jDfeMFtgArVChRqbc+21wV8v0i6wlqFj7tzw/4ho/vB1V4Ubq+NyGcaf/+z/eSYlBe7uSkoy39trrxnGDTc0tfKkpRnG9dcbxlNPGcaePcf3s3US33fWm2++aXUpjkGYge3wxRob0QTD9tCVFgux+t2LdBC7r3vob38zWyiKi8N3FaWlRde6Fu4xd655flu7qBL56NXLMA4fPv6fs935vrNmzVpoVPEvuIgQZmA7fLHGRlu67JzYlRYrsWwVjCQU1dWZQaJ5S0WoAbwtH7fd1nStaFpWWj7S080QdcIJ1oeVSB4eT/v/u8D3nXXNNYuM0tJSq8txBJYzgO0EWucn2rWP0LY1l3z3/HDyrSy8XvP3xuuN7rxIFtyM9PVDrULuq8u3mGnz+xgFu6dRIA89JN16q7Rjh9StW/CfdTjV1dKJJ0oHD7bt/ETzes17DgHNEWZgW+3hi9VKsV7/ye7q6807N+fkmHe4zckxn0d6F+BYLf4ZLhTt3h16MdNorFhh3pn3pJOkYcPavpL40aPHX0siPfFE9GEV7RthBmjHli2T5s5tCi4ej3nH3Rkz2t+Xga+lwxckqqvN5/PnR3Z+rMJfqFAkmXcknjUr9Npf0aqulv72N/PaaWmxu65d1dVF3lKGjoEwA7RjzbvsduyQbrhBevRR81/z0bZc2FmkXTvhBAp/c+e2XnAzXFfWlVcGbyWprjaXAEhKiqymSBmGua7Wvn3SiBGxvbbdpKVF3lKGjoEwA3QAHo/05JPSgw+2veXCTkpKpLfeMv+UYjfeJdx4rcpK6frrA3dlNe/meuwxcy2nUIElmvExkfJ6zRrff99cd6m9uvXW9tdNGkiXLoY6depkdRmOwJBKoAMI13KxcKEzvhxqaqTx46UPP2zaNnas9OqrZtdOoEATzXiX5uc0X/zQtxDn/ff7hxBfIPRpvhBmpGHF5TJbVWLB917T0qQPPjDD3tat0ssvS7/7nf/n4/GYq6Nv3mzPlb2DmT27dUtZe3X++WezsGSEaJkBOoBYtVxYrWWQkczn06bFd7Dz/PnS8uWBA0pDgxkUA4XFSKSlSe++Kx3vP8ADvdecHOmcc8zBxiUlTa1Nvj//+lf/brX0dDMcxmvmoMvVtvOSk6Wf/1yqqJAKCzvOzMa0jjAAKkYIMw7T1mmn6NhiNVMnWi27g473Wi2DjM+HH5oDmyMZ7xItX6tWqNaT6urgYVEK/SVeXS316WPWH81spKuvju69+lqbcnKaZgm27FYrKTFbdA4dkq65xr+bLDnZrHHLFvNRUOD/+rNnm+Oy9u8PfG5BgTRnjn9wuuoqs0usqEiqqjIfmzdLr71m1lRVZdZVUSE9+6yUkRH554MOxuob3SRCe7hpXqR3FAWCSeSdlQOtQzR2rLm9rd58M/TN1P7yF/O4WN/4L5Ib0qWnB7/hXnq6uXRBqJvABVoBOz29afHKYOfE+yaHvjsUFxUFfo1Qrx/s3I58Y8ZIsTZT9GiZcYjjnXYKRDpTJxaCdQeNH9/2aw4bFnp/bq75Z6zvTxRuqrXbbXZxBevmmjnT7OYpKAjdDRaolSTcOfG+F5PHIw0ZYj4CvUao1w92LvePQlxYnaYSwektMyy+iFiK97+Mi4tDt2IUF7f92sFWnR47Nnb1BxKoVUsyW058LaThluFoyzIdLO3RMdEyEz2XYcRqHL19bd++Xbm5uSoqKtKQIUOsLidqu3aZ00BD7W8+8wKw0ltvmYNOg/nLX9reQhNsNtPbb8f3ZnG+2Uy+e9akp5v3klm+vPU4Dt+A6l69Arc+hNsfSFvOgXP5vrM2bdqkcePGWV2OI3SQMeHO5mvmjtW0UyCeIu0OaovmU46Lisxr5eS0/XqR8nUBLVwYPlS0nNYd7f5YnQN0JIyZcYCOtsYOnC0nJ/gN28aOjU34yMkxW2gSEWSaY7wHYE+EGYdI5OBN4Hi9/XbrQOPrDopGe7wVQXt8T8219/cHeyLMOES426wDduLrDiouNsfIFBebzyMd13K8K2DbUXt6T4ECi+/9ZWeb7y8725yNtWMHwQbxR5hxGJq54SRt7Q5qj7cimDfP/u8pXKtKqEB2113Svfc2rQZeUyM98EDki5q2fO3mz2ntQTiEGQC2EqsVsO2ivt5soSgstO97irTVKFjIvOMOM7gEU11tzvwKFNxatuh07y6NGWP+OWiQOVssI8P5rVmIL8IMAFtpL+tI+cyfb65WHowd3lMkLWGhQubKleEX1jQMM9BVVjZdb9cu6fbb/Vt0amvNJQ1qa83nx441XduOrVmwB8IMAFuxah2peIhkXadEv6dA3TmRtISFCpm+4BFOfb25PlPzVqBQQS8Qu7RmwV4IMwBspT3diiBUAJAS+56CdSXt2xdZS1iokJmeHvlkhCef9G8Fags7tGbBXggzAGzHybciaN7yEW5dp1mzEveegnUlPf54ZC1hoULmzJnmewm1OrjPsWOtW4GilZbmrBY6xB9hBoDtOPFWBIFaPpYskW6+uXUAcLmk2bOl++9PzHsK1ZX0299KN94YWUtYqJD5i1+Y419ChbdYuekmZ7XQIf4IMwBsy0m3IgjW8iG1DgC+Qa+JEm5Q9bXXRtYSFipk+vaVlJj7Aq347XIdf3gbO9Z8HaA5FpoEgOPk9ZotMcHWTysuNv/bqsUiI6nP44ntgpYtF+f0eMyWnoaGwNPUk5PNc5KSzNDT8r/T0swWpHvvtXcLXSyw0GT0bNcys23bNk2bNk19+vSR2+3WW2+91eqY8vJy5efnKysrS927d9cVV1yhiooKC6oFgMimk1vZyhTpoOpY1hisFecXv2jdCnTHHdKhQ+ZxlZVSRUXr/z50yAxB7T3IoG1sF2ZSU1P1k5/8RK+88opcQUaT5efnq7i4WF988YV27typAwcOaPr06QmuFABMTphObtWg6pYBKVjIychoOq75OU7qaoR1bJdxTzvtNJ122mmSpEA9YHv37tVrr72mbdu2KSsrS5JUWFioESNG6KuvvlLfvn0TWi8A+Fo+7rvPv/vETtPJfSFi4ULrurua84UUIBZs1zITzpYtW9SpUyfl5uY2bhs2bJhSU1O1ZcsWCysD0JE5ZTo5LR1ojxIWZmbMmCG3262kpCS53e5WjwkTJkR0ncrKSmVmZrbanpmZqUrffbIBIMGcOJ0caC8S9r/ZypUrVVhYGHR/SkpKRNfJyMgIONi3vLxcGRkZIc8tKCjwOyYvL095eXkRvS4ARILuE8TKggULlJ2d3fic76zgEhZmPB6PPDFo1xwxYoRqa2tVVFTU2NW0bds21dXVacSIESHPLSwsZGo2AMARli5dytTsCNlyzExtba1q/rWEal1dnWpra3XsX8umnnTSSZo2bZrmzJmjQ4cOqaSkRHPnztWFF17I4F8AUWm56CIAZ7JdmNmzZ4/S09PVuXNnuVwuTZs2TR6PR//5n//ZeMzq1auVk5OjU045Raeeeqp69uypVatWWVg1ACcJtuhifb3VlQFoC9sNTevfv78awqxClpmZqWeeeSZBFQFob3xLD/j+qmm+9AC3ygecx3YtMwAQT6EWXfTdeh+x5fVKRUXmo/nnG6qbjy5ARIMwA6BDiWTpAbRNywBSX28uqpmRIQ0daj66dZPmzDG3B+rmowsQbWG7biYAiCff0gPBFl20w9IDwXi9Zhjr3ds+N73zeqV9+6Tf/U76zW/MzzU93bwjckNDU/edT329ucaSyyX5bvLevJtPogsQ0aNlBkCHEumii3Zix9aK5jWddpoZUHwBsbraXN36/vuDn99ytZqGBrP7jy5AtAUtMwA6HN8SA74vSI/HDDJ2W3rAx44DllvWFEiA5fVCCtb9JzV1AXJDQgRCywyADsdJSw/YccBysJqOV3q6/Vcfhz2FDDO1tbXaunWrqgPE5eeffz5uRQFAIjhh0UU7DlgOVVOkXC7/52632f3ntC5A2EPQMPPpp59qwIABGjlypHr27Kn//u//9tt/3XXXxb04AOjofAOWA7GqtSJUTZG49VZzRlOgFcadsvo47CVomJk3b57y8/NVVlamJ554QnPmzNGjjz7auN+ItjMUABA1Ow5YDlZT8/1jxwbeP3u29NBD0vLlgbv5nNQFCPsI+uvxt7/9TWvXrlWnTp106aWX6rTTTtPEiRPVpUsXXXHFFYmsEQA6NDsOWA5U0/XXS9ddJ/XtK6WmmoOEQ9UcaoVxVh9HNIKGGd9Cjz7Dhg3TunXrNHXqVHk8HrladngCAOLC11qxcKE5RqZXL+vHj0RSk91qRvsVtJtp0KBB+vvf/+63bcyYMVq7dq1mzJgRcFAwACB+7DhgOVxNdqwZ7U/QMJOfn69333231fZzzjlHq1atUr9+/eJaGAAAQCSCdjPNmjUr6EmXXHKJLrnkkrgUBAAAEA1umgcAABwt7GS3mpoaLV26VK+//roOHjzoNyV77969cS0OAAAgnLAtM7fffrvWrFmj/Px8lZSUaPbs2UpNTdW1116biPoAAABCChtmXnrpJb388su67bbblJqaqttuu01r1qzRe++9l4j6AAAAQgobZsrKyvTd735XkpSUlKRjx45p1KhRev/99+NeHADAObxe8669bV388njPR8cVNsz07t1bX3/9tSSpf//+2rRpkz799FMlc29pAICk+npp3jwpJ0caNMj8c948c3tLgQJLZaV59+BIzgcCCZtILr/8cr399tvKz8/Xtddeq4kTJyo5OVnXX399IuoDANjc/PnSffdJDQ3m8+pq87lk3gVYMoPJ/PnSihXm/vR06eabzX0PPCAdO9Z0vUDnA6G4jChXjPzggw9UUVGhyZMnO2ZJg+3btys3N1dFRUUaMmSI1eUAQLvh9ZotKYFuCu/xmAtFejxmS0vzwBOJ5ud3JL7vrE2bNmncuHFWl+MIYVtmamtr5Xa7lZKSIkn6wQ9+oLq6Oh09elSdOnWKe4EAAPvavz9wkJHMoONbl2nFiuiCTPPzWXAS4YQdMzNt2rRWg33ff/99nX/++XErCgDgDL17m11GgXg8ZpAJFXhC8Z0PhBM2zGzdurVVM9e4ceP08ccfx60oAIAzeDzSzJmSu8W3idst3XKLuT9U4Amm+flAOBEtZ1DfYkh5fX29ohxqAwBop5Ytk+bObQoeHo/5fNmypueBAo8kBRp6mZzsfz4QTtgwM3z4cD311FN+255++mkNHTo0XjUBABwkOdmcdVRcbE67Li42nze/g0ewwDNnTtO29HTpuuukQ4danw+EEvZXZdmyZTrnnHP06quvavDgwdqxY4feeOMNvfHGG4moDwDgEB5P8MG6vsCzcGHToGBfiFm8uPU2IBphW2Z++MMf6u9//7v69++vzz//XP3799ff//53posBAKLmCzzNQ0ugbUA0IhozU1FRoerqah09elTV1dUqLy+Pd10AAAARCRtmVq9erfHjx+vIkSMaNWqUjhw5onPOOUdPP/10IuoDAAAIKaIxMy+++KLOPffcxm3r16/XLbfcoiuvvDKuxQEAAIQTtmVm//79mjJlit+2yZMn69tvv41bUQAAAJEKG2YmTZqk9evX+23bsGGDJk2aFLeiAAAAIhW2m6lPnz7Ky8vTtGnTNHDgQO3evVuvvvqqrrrqKi1cuLDxuCVLlsS1UAAAgEDChpmioiKNGTNGJSUlKikpkSSNHj1an3zySeMxTlk9GwAAtD9hw8xf/vKXRNQBAADQJhHdZyaRVq9erR/96EfKzs5Wjx49NGHCBL333nt+xxw9elQ33XSTevTooW7duunCCy/UV199ZVHFAADASrYLM0eOHNGiRYu0d+9eHThwQBdddJGmTp2qb775pvGYWbNmadOmTfr444/19ddfKysrSxdeeKGFVQNAx+H1mmsweb3OuC7aP9uFmRtuuEGTJk1S586dlZSUpFtvvVVJSUnavHmzJKm2tlZPPfWUli1bpr59+6pLly564IEHVFRUpE2bNllcPQC0X/X10rx5Uk6ONGiQ+ee8eeZ2O14XHYftwkxLH374oaqqqjR8+HBJ0o4dO1RTU6PRo0c3HpOdna0BAwbo448/tqpMAGj35s+X7rtPqq42n1dXm8/nz7fnddFxJCzMzJgxQ263W0lJSXK73a0eEyZMaHXOvn37dPnll+vOO+/UySefLEmqrKyUJGVmZvodm5WV1bgPABBbXq+0YoXU0OC/vaFBevjhtncNxeu66FjCzmaKlZUrV6qwsDDo/pSUFL/nO3fu1OTJk3X55ZfrnnvuadyekZEhSSovL1fPnj0bt5eVlTXuC6agoMDvmLy8POXl5UX1PgCgI9q/v6nlpCWvVzpwwFz52i7XbQ8WLFig7Ozsxud8ZwWXsDDj8XjkiXB9923btmnq1Km6+eabddddd/ntGzx4sNLS0rR582adf/75kqSSkhJ9+eWXGjlyZMjrFhYWasiQIW17AwDQgfXuLaWnBw4eHo/Uq5e9rtseLF26VOPGjbO6DEew3ZiZ9957Tz/+8Y81b968VkFGkjp16qQZM2Zo4cKF2rdvnw4fPqyCggLl5ubqjDPOsKBiAGj/PB5p5kzJ3eJbw+2WbrnF3G+n66JjsV2YmT9/vioqKjR//nx17dpVXbt2VUZGhn71q181HvPAAw/ojDPO0MiRI3XiiSeqtLRUL7/8soVVA0D7t2yZNHduU8DweMzny5bZ87roOFyGYRhWFxFv27dvV25uroqKiuhmAoDj5BvL0qtXbFtO4nVdp/F9Z23atIlupgglbMwMAKB98HjiMyg3XtdF+2e7biYAAIBoEGYAAICjEWYAAICjEWYAAFFhQUjYDWEGABARFoSEXTGbCQAQEd+CkL51lHwLQkpSs1uBAVCp1wEAABhfSURBVAlHywwAICwWhISdEWYAAGFFsiAkYBXCDAAgLN+CkIF09AUhYT3CDAAgLBaEhJ0xABgAEBHfwo++MTIejxlkWBASViPMAAAikpxszlpauJAFIWEvhBkAQFRYEBJ2w5gZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaIQZAADgaLYLMy+//LKGDx+u7t27q3v37vr+97+vF154we+Y8vJy5efnKysrS927d9cVV1yhiooKiyoGAABWsl2YGT16tNavX6/S0lKVlpbqwQcf1BVXXKFPPvmk8Zj8/HwVFxfriy++0M6dO3XgwAFNnz7dwqoBAIBVkq0uoKXevXs3/rdhGHK5XJKkf/7znxo6dKj27t2r1157Tdu2bVNWVpYkqbCwUCNGjNBXX32lvn37WlI3AACwhu3CjCRVVlaqf//+8nq9qqur05lnnqnzzjtPkrRlyxZ16tRJubm5jccPGzZMqamp2rJlC2EGAIAOJmHdTDNmzJDb7VZSUpLcbnerx4QJExqPzcjIUFlZmQ4fPqwXXnhB06ZNU2pqqiQz6GRmZra6fmZmpiorKxP1dgAAgE0krGVm5cqVKiwsDLo/JSWl1bbU1FRdcsklOu+889SlSxfddNNNysjICDjYt7y8XBkZGTGtGQAA2F/CwozH45HH42nTuXV1ddqxY4ckacSIEaqtrVVRUVFjV9O2bdtUV1enESNGhLxOQUGBX+DJy8tTXl5em2oCACCeFixYoOzs7MbnfGcF5zIMw7C6iOZWr16tH/zgBzrllFN09OhRPfXUU7rlllv0yiuvaOrUqZKkCy64QHV1dXr22WdlGIby8/Pl8Xj0xz/+MeA1t2/frtzcXBUVFWnIkCGJfDsAAETF9521adMmjRs3zupyHMF2U7N37dqlKVOmqFu3burXr59Wr16t559/vjHISGbgycnJ0SmnnKJTTz1VPXv21KpVqyysGgAAWMV2s5kWL16sxYsXhzwmMzNTzzzzTGIKAoAOxuuV9u+XeveW2jg6AEgo27XMAACsUV8vzZsn5eRIgwaZf86bZ24H7Mx2LTMAAGvMny/dd5/U0GA+r642n0vSr35lXV1AOLTMAADk9UorVjQFGZ+GBunhh839gF0RZgAA2r/fbIkJxOuVDhxIbD1ANAgzAAD17i2lpwfe5/FIvXolth4gGoQZAIA8HmnmTMnd4lvB7ZZuuYVZTbA3BgADACRJy5aZf/rGyHg8ZpDxbQfsijADAJAkJSebs5YWLjTHyPTqRYsMnIEwAwDw4/FIAwdaXQUQOcbMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAAAARyPMAC14vdKuXeafAAD7I8wA/1JfL82bJ+XkSIMGmX/Om2duBwDYF2szAf8yf750331SQ4P5vLrafC6Zi+8BAOyJlhlAZpfSihVNQcanoUF6+GG6nADAzggzgKT9+82WmEC8XunAgcTWAwCIHGEGkNS7t5SeHnifxyP16pXYegAAkSPMADIDy8yZkrvF/xFut3TLLeZ+AIA9MQAY+Jdly8w/fWNkPB4zyPi2AwDsiTAD/EtysjlraeFCc4xMr160yACAExBmgBY8HmngQKurAABEijEzAADA0QgzAADA0QgzAADA0QgzAADA0QgzAADA0QgzAADA0QgzAADA0QgzAADA0QgzAADA0WwdZh566CG53W4tXLjQb/u+fft0wQUXKCMjQyeccIJuueUW1dfXW1QlAACwkm3DzI4dO/Twww9r2LBhftsNw9B5552nnJwc7d+/Xx999JE2btyouXPnWlQpAACwki3DTENDg6ZPn64HH3xQWVlZfvs2btyoHTt26IEHHlDnzp3Vr18/LV26VE888YTq6uosqhgAAFjFlmHmF7/4hU499VRdeOGFrfZt3bpVAwcO9As5o0ePVlVVlXbs2JHIMgEAgA0kLMzMmDFDbrdbSUlJcrvdrR4TJkyQZIaVJ554Qg8//HDA61RWViozM9Nvmy/YVFZWxvdNAAAA20lO1AutXLlShYWFQfenpKSovr5eV155pR566KFWgcUnIyND5eXlftvKysoa9wEAgI7FZRiGYXURPnv27NHAgQOVnZ0tX1kVFRVKSUnRwIED9cknn2jjxo2aPHmy9u/f39gi8/LLLys/P1+HDh1Sampqq+tu375dubm5mjJlil/gycvLU15eXmLeHAAAEfB9Z02YMEHZ2dmN2/nOCs5WYcYwDO3fv99v209/+lONHTtW8+bNU8+ePWUYhkaOHKlRo0ZpxYoVKi0t1UUXXaTx48frwQcfDHhd3y9GUVGRhgwZkoi3AgBAm/i+szZt2qRx48ZZXY4jJKybKRIul0t9+vTx25aWlqauXbuqZ8+ejce88soruuGGG9S7d2+lpaXp5z//uZYvX25FyQAAwGK2CjOBvPXWW6229evXT+vWrbOgGgAAYDe2nJoNAAAQKcIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNMIMAABwNNuFmXfeeUdut1sZGRnKyMhQ165dddJJJ/kdU15ervz8fGVlZal79+664oorVFFRYVHFAADASrYLM5LkcrlUUVGhyspKHT58WHv37vXbn5+fr+LiYn3xxRfauXOnDhw4oOnTp1tULQAAsFKy1QUE09DQoKSkpFbb9+7dq9dee03btm1TVlaWJKmwsFAjRozQV199pb59+ya6VAAAYCFbtsxI0sCBA9WrVy9NmjRJGzdubNy+ZcsWderUSbm5uY3bhg0bptTUVG3ZssWKUgEAgIUSFmZmzJght9utpKQkud3uVo8JEyZIkk477TRt2bJFu3fv1q5duzR16lRNmTJF27ZtkyRVVlYqMzOz1fUzMzNVWVmZqLcDAABsImHdTCtXrlRhYWHQ/SkpKZKknj17qmfPnpKkzp07q6CgQOvWrdOaNWs0bNgw/f/27jUmiqsPA/izy2V1ZReQQbFquWmtFRGt1GpsdLWVhptGS0JD0dg0Jl6wtEpSrUraSDVaFYt+kJi2Fv1gMFWst1ZrqqnY1oiiS42VqKBUWmm5tCAruP/3Ay/7ii590cLOjvv8EiJ75sz6n5Mx+3jmzI7ZbHa62Leurg5ms/kfa1iyZEmHPikpKUhJSXmcwyEiIupRK1euRFBQkOM1P7M657IwYzQaYTQaH2tfvV4PEQEAxMTEwGazwWq1Oi41XbhwAS0tLYiJifnH99mwYQNGjBjxWDUQERG50tq1axEbG6t2GZrgdmtmvvnmG1y/fh0igjt37mDz5s0oLi7GrFmzAABPP/004uPjsXTpUvzxxx+oqalBVlYWkpOTufiXiIieGAaDQe0SNMPtwsxPP/2ESZMmwWQyITQ0FPv378eRI0cwZswYR5+CggIoioLIyEgMHToU/fv3x44dO1SsmoiIiNSik/brN0+wsrIyREVFwWq18jITEVE3amoCbt0CBgwAHnMlAT2g/TOrtLQU0dHRapejCW43M0NERO6vtRV47z1AUYAhQ9r+fO+9tnYiV3PbL80jIiL3tWIFsH49YLe3vb5zp+01AKxdq15d5Jk4M0NERI+kqQn45JP/BZl2djuQl9e2nciVGGaIiOiR3LrVNhPjTFMTUF3t2nqeVM4e6UPOMcwQEdEjGTAA6N3b+TajEQgJcW09RAwzRET0SIxGYPFiQP/AJ4heD2Rk8K4mcj0uACYioke2enXbn+1rZIzGtiDT3k7kSgwzRET0yLy92+5aWrWqbY1MSAhnZEg9DDNERPTYjEYgIkLtKsjTcc0MERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaRrDDBEREWkawwwRERFpGsMMERERaZpbhpmqqiq88cYbUBQFZrMZ0dHRsFqtju11dXVIS0tDYGAg+vbti/T0dNTX16tYcfcpLCxUu4QnBsey+3Asuw/HsvtwLKmd24WZ2tpaTJw4EU899RTKy8vR0NCAvXv3IiQkxNEnLS0Nt2/fxtWrV1FeXo7q6mrMmTNHxaq7D/9xdh+OZffhWHYfjmX34VhSO2+1C3jQxo0boSgK1q1b52iLjIx0/F5ZWYnDhw/jwoULCAwMBABs2LABMTExuHnzJgYNGuTymomIiEg9bjczc+zYMURGRmLmzJkICgrC8OHDsXr1aogIAOD8+fMwGAyIiopy7BMdHQ1fX1+cP39erbKJiIhIJS6bmZk7dy527NgBnU7nCCb3mzx5Mo4fP46amhqcOXMGBQUFKCwsRFlZGRITE2EwGJCVlYWGhgYEBAQ8tH9AQAAaGhqc/t02mw0AUF5e3r0H1QMaGhpQVlamdhlPBI5l9+FYdh+OZffRylhGRkaiV69eapfxRNOJs2TRA5qamtDc3Nzpdh8fH5hMJjz//PPw9fXF6dOnHdvWrl2LoqIinD59Gvv370dqaiqampo67N+rVy/s2bMHiYmJD713UVERZsyY0X0HQ0RE1EVWqxUjRozocv+ysjJERUUhLi4OZrPZ0Z6SkoKUlJSeKFHzXDYzYzQaYTQa/2+/MWPG/GPSjomJgc1mg9VqdVxqunDhAlpaWhATE+N0n0mTJmHfvn0YPHgwDAbD4x0AERHRY7h/3WdX+1utVs7oPAKXzcx0VUlJCSZMmIAvvvgCr732Gi5duoSEhARkZmYiMzMTAJCUlISWlhbs2rULIoK0tDQYjUbs3btX5eqJiIjI1dwuzADAwYMHsWzZMly7dg0hISGYN28esrKyHNvr6uqwaNEiHDhwADqdDklJSdiyZUuH6TgiIiLyDG4ZZoiIiIi6yu1uzSYiIiJ6FAwzREREpGkMM27Abrfj/fffR1hYGPz9/TF8+HDk5+d36HPjxg0kJSXBbDajX79+yMjIQGtrq0oVuzdPfrZXT8nNzYVer8eqVas6tPO87JqCggJMnDgRQUFBCA4OxpQpU1BcXNyhz927d7Fw4UIEBwfD398fycnJuHnzpkoVu7fs7GwMHDgQJpMJkydP1sR3zVDPYphxA1u3bsX27dtx6NAh1NfXY9u2bcjMzMTRo0cBACKChIQEKIqCW7du4ezZszh58mSHRdHUxtOf7dUTLl++jLy8PERHR3do53nZdX///Teys7NRWVmJ6upqTJ8+Ha+++ip+/fVXR5933nkHp06dwrlz51BVVYXAwEAkJyerWLV7Wr9+PT7//HMcPXoUNTU1mDBhAuLi4h767jHyMEKqe/vtt2XmzJkd2saOHSvr1q0TEZHvvvtOfH195c8//3RsLyoqEj8/P7l7965La3V3K1askLFjx3a6vaKiQnQ6nVy8eNHRVlpaKjqdTm7cuOGKEjXl3r17Mm7cOCkqKpLJkyfLypUrHdt4Xv47AQEBsm/fPhERaW5uFqPRKF999ZVje01Njfj4+Mj333+vVoluKTw8XPLy8hyvW1tbJTg4WHbu3KliVaQ2zsy4gXnz5uGXX37B+fPnISL49ttvcfXqVcTHxwMASktLERER4XiwJgDExsaisbERly9fVqtst8Rne3Wvjz76CEOHDnU6Q8Dz8vH9+OOPaGxsxKhRowC0zX41NzcjNjbW0ScoKAjh4eE4d+6cWmW6nYaGBly/fr3DOHl5eWH06NEcJw/HMNOD5s6dC71eDy8vL+j1+od+pkyZAgAIDw/HK6+8grFjx8JgMCAhIQE5OTmOr7929jyq9g+Qzp5H9aTp6ljW1NRgz549SElJwe+//47du3cjPz8fH3/8MQDnYwn887O9njRdHcvS0lJs374deXl5Tt+H52XXx/J+N27cQGpqKpYtW4awsDAA/xsvZ+PpKWPZFRwn6ozLHmfgibZu3YoNGzZ0ut3HxwcAsGDBAlitVly5cgXh4eGwWq2YPn069Ho95s2bB7PZjLq6ug771tbWAoDHfFFgV8fSbDYjNjYWr7/+OoC2WZcFCxbgyy+/RFZWFsxms9PFvnV1dRzL//Lx8UFraytmz56N3Nxcp+EPAM9LdP28bFdeXo5p06YhNTUVH3zwgaO9fbzq6urQv39/R3ttba3HjGVX3D9O96utrcWgQYPUKInchdrXuUhk5MiRkpub26Ht3Xfflfj4eBEROXHihBgMBqdrE2w2m0trdXdvvfWWjB8/vkPbmjVr5MUXXxSRtjUzer3+oTUzer2ea2buc/36ddHr9RIcHCyKooiiKOLj4yNGo1GioqJEhOfloyotLZUBAwZITk7OQ9ucrZm5ffu2+Pr6cs3MA5ytmenXrx/XzHg4hhk3MH/+fHnhhRekoqJCRER+/vlniYyMlFWrVomIiN1ul1GjRsncuXPlr7/+koqKComJiZHMzEw1y3ZLZ8+eFYPBILt375Z79+6J1WqV0NBQ2bRpk6NPYmKixMXFSU1Njdy+fVumTZsmM2bMULFq92O326WqqqrDz/jx4yUzM1Oqq6sdfXheds2pU6ekb9++snnz5k77LFy4UEaPHi2VlZXS0NAgs2fPljFjxriwSm1Yv369hIaGitVqlaamJlm+fLkMGjRIGhsb1S6NVMQw4wYaGxslIyNDBg8eLCaTScLCwmTp0qUd7giprKyUhIQE8fPzE0VRZPHixbxjpBMHDhyQkSNHip+fnwwZMsRxV1i72tpaSUtLE39/fwkICJD09HSpr69XqVrtsFgsHe5mEuF52VUWi0W8vLzEZDKJn5+f+Pn5iclkkjVr1jj62Gw2WbRokQQFBYnJZJLExES5efOmilW7r+zsbAkJCZE+ffrIpEmTxGq1ql0SqYzPZiIiIiJN491MREREpGkMM0RERKRpDDNERESkaQwzREREpGkMM0RERKRpDDNERESkaQwzREREpGkMM0RERKRpDDNERESkaQwzRPSvHT9+HC+//DKCgoKg1+tx9epVtUsiIg/CMENE/1qfPn0wZ84c7Ny5EzqdTu1yiMjDMMwQeQiLxYKMjAzMmjULZrMZw4YNQ0FBgWP76dOnMXXqVCiKAkVRMHXqVNhsNgBAdnY2hg0bBrPZjNDQUCxevBjNzc2OfceNG4f09HQ899xzLj8uIiJvtQsgItf59NNPUVhYiMLCQnz99deYMWMGhgwZAn9/f0ydOhUbN27EwYMH4e3tjeLiYuj1bf/feeaZZ3D8+HEMHDgQly5dQnJyMkwmE3JyclQ+IiIigE/NJvIQFosFiqKgsLDQ0Zaamgo/Pz/07t0bFRUV2L9/f5feKzc3F7t27cKZM2c6tFdUVCAiIgJXrlxBREREt9ZPRNQZzswQeZAHA0Z4eDhKSkrg6+uLZ599ttP9tm3bhvz8fFRUVODevXu4e/cuFEXp6XKJiLqEa2aIPMi1a9ceej148GCEhYXh8uXLTvf54YcfkJGRgU2bNuG3335DbW0tcnJywEldInIXDDNEHuTQoUM4fPgw7HY7jhw5gqKiIrz55puYP38+jh07hvz8fDQ3N6O1tRUnT55ES0sL6uvr4e3tDUVR4OXlhZKSEmzZsqXD+4oIbDYbmpubHb/bbDbY7XaVjpSIPAnXzBB5CIvFgpEjR6KqqgpHjx5F//79sXLlSsyePRsAUFxcjOXLl+PixYvQ6XQYPXo0Dhw4AF9fXyxZsgQFBQVobW3F+PHjMWHCBOTn56OyshIAcOLECVgsloduy/7ss88c709E1FMYZog8hMViwUsvvYQPP/xQ7VKIiLoVLzMRERGRpjHMEHkIfjMvET2peJmJiIiINI0zM0RERKRpDDNERESkaQwzREREpGkMM0RERKRp/wEeCSKxHPEpsAAAAABJRU5ErkJggg==\" class=\"pd_save\"></center>\n",
       "                        \n",
       "                    \n",
       "                \n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# Try to plot the PCA projections backing to rdd and recreating the df\n",
    "pca_rdd_raw = transformed_pca.select('pcaFeatures').rdd.map(tuple)\n",
    "pca_rdd = pca_rdd_raw.map(lambda row: (float(row[0][0]),float(row[0][1])))\n",
    "print(\"This is the RDD containing pca features: \",pca_rdd.take(1),\"\\n\")\n",
    "\n",
    "# Once we have the RDD, a new DF is created, again we create an schema\n",
    "names_PCA = [\"pca1\",\"pca2\"]\n",
    "fields_PCA = [StructField(field_name, FloatType(), True) for field_name in names_PCA]\n",
    "schema_PCA = StructType(fields_PCA)\n",
    "\n",
    "# And with the schema, we create the dataset\n",
    "pca_DF = spark.createDataFrame(pca_rdd,schema_PCA)\n",
    "\n",
    "# Add indices to dataframes to join them in column sentiment \n",
    "reviews_DF = reviews_DF.withColumn(\"rowId1\", monotonically_increasing_id())\n",
    "pca_DF = pca_DF.withColumn(\"rowId2\", monotonically_increasing_id())\n",
    "pca_DF_plot = reviews_DF.join(pca_DF, reviews_DF.rowId1 == pca_DF.rowId2, 'inner').select(reviews_DF.sentiment, pca_DF.pca1, pca_DF.pca2)\n",
    "\n",
    "# Print some flavours\n",
    "pca_DF_plot.printSchema() \n",
    "pca_DF_plot.show(5)\n",
    "\n",
    "# Visualize scores with pixidust\n",
    "display(pca_DF_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Create training and test set \n",
    "\n",
    "Training, validation and test set are split. We want to see our model generalizing in unseen cases and thus, data for testing phase must be stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for the analysis: \n",
      "+-----+--------------------+--------------------+---------+-----+\n",
      "|score|             summary|                text|sentiment|label|\n",
      "+-----+--------------------+--------------------+---------+-----+\n",
      "|  0.0|   Not as Advertised|Product arrived l...| negative|  0.0|\n",
      "|  1.0|      Cough Medicine|If you are lookin...| negative|  0.0|\n",
      "|  3.0|          Nice Taffy|I got a wild hair...| positive|  2.0|\n",
      "|  4.0|    Healthy Dog Food|This is a very he...| positive|  2.0|\n",
      "|  0.0|My Cats Are Not F...|My cats have been...| negative|  0.0|\n",
      "+-----+--------------------+--------------------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Training-set count: 171102\n",
      "Test-set count: 42517\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Just store text, summary, sentiment and label\n",
    "df = reviews_DF.drop('scoreName')\n",
    "df = df.withColumn(\"label\",when(col(\"sentiment\")=='positive',2.0).when(col(\"sentiment\")=='neutral',1.0).otherwise(0.0))\n",
    "df = df.withColumn(\"score\",df[\"score\"].cast(DoubleType())-1)\n",
    "final_df = df.drop('rowId1')\n",
    "print(\"DataFrame for the analysis: \")\n",
    "final_df.show(5)\n",
    "\n",
    "# Data is split in training and test with a 80:20 ratio\n",
    "train_set, test_set = final_df.randomSplit([0.8,0.2])\n",
    "\n",
    "# Training and test set\n",
    "print (\"Training-set count:\", train_set.count() )\n",
    "print (\"Test-set count:\", test_set.count() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare datasets downsampled to compare the effect of training models with dataset of different sizes. Initially we are going to train in roughly 2000 (1% of original) and 20000 (10% of original) examples. We are training in all possible dataset and testing the behaviour in the remaining reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set count of small 1: 2170\n",
      "Test-set count of small 1: 210393\n",
      "Training-set count of small 2: 21139\n",
      "Test-set count of small 2: 192288\n"
     ]
    }
   ],
   "source": [
    "# Datasets of different sizes\n",
    "train_small_1, test_small_1 = final_df.randomSplit([0.01,0.99])\n",
    "train_small_2, test_small_2 = final_df.randomSplit([0.1,0.9])\n",
    "\n",
    "# Print the number of items in each dataset\n",
    "print (\"Training-set count of small 1:\", train_small_1.count() )\n",
    "print (\"Test-set count of small 1:\", test_small_1.count() )\n",
    "print (\"Training-set count of small 2:\", train_small_2.count() )\n",
    "print (\"Test-set count of small 2:\", test_small_2.count() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Classification by score\n",
    "\n",
    "The first set of experiments is create a prediction model to predict the score given by user to a certain product. Initially we expect to see some sort of relation between score and language style, and the model would not perform quite well, as everyone does not rate the same way or are prone to give extreme scores.\n",
    "\n",
    "The analysis will be performed with three different classification algorithms: Naive Bayes, Logistic Regression and Random Forest. Accuracy will be used as the main metric, but further parameters will be investigated in the final models. Performance needs to be deeply evaluated and the following function will be employed to do so.\n",
    "\n",
    "Notice that score is labeled as 1: 0.0, 2: 1.0, 3: 2.0, 4: 3.0 and 5: 4.0. This is due to the fact that data needs to be tailored to the functions used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def evaluatePerformance(model,data,outputCol,possibleLabels):\n",
    "\n",
    "    # Predictions on test set\n",
    "    test_predictions = model.transform(data)\n",
    "\n",
    "    # Show some information of the created dataset\n",
    "    test_predictions.select(\"text\",outputCol,\"prediction\").show(5)\n",
    "\n",
    "    # Parse data into RDD to metrics analysis\n",
    "    test_predictions_rdd = test_predictions.select(outputCol,\"prediction\").rdd.map(lambda row: (row[0],row[1]))\n",
    "    print(test_predictions_rdd.take(4))\n",
    "\n",
    "    # Metrics to analyse the data\n",
    "    metrics = MulticlassMetrics(test_predictions_rdd)\n",
    "\n",
    "    # Summary stats\n",
    "    for label in possibleLabels:\n",
    "        print(\"\\nRecall of label \",label,\" is: \",metrics.recall(label))\n",
    "        print(\"Precision of label \",label,\" is: \",metrics.precision(label))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    confusionMatrix = metrics.confusionMatrix().toArray()\n",
    "    print(\"\\nConfusion Matrix: \\n\")\n",
    "    print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First experiment:** Classification of score using Random Forest on text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.54 s, sys: 2.39 s, total: 10.9 s\n",
      "Wall time: 58min 41s\n",
      "Accuracy of the best fitted model on training set = 0.4454605482285708\n",
      "Accuracy of the best fitted model on test set = 0.42342786104660707\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|score|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|We bought a carto...|  0.0|       4.0|\n",
      "|We bought a carto...|  0.0|       4.0|\n",
      "|The new flavor is...|  0.0|       4.0|\n",
      "|These noodles wer...|  0.0|       0.0|\n",
      "|Sunday breakfast ...|  0.0|       2.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 4.0), (0.0, 4.0), (0.0, 4.0), (0.0, 0.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.4555661729574773\n",
      "Precision of label  0.0  is:  0.37177112779023297\n",
      "\n",
      "Recall of label  1.0  is:  0.9954128440366973\n",
      "Precision of label  1.0  is:  0.03684836135167261\n",
      "\n",
      "Recall of label  2.0  is:  0.5466531440162272\n",
      "Precision of label  2.0  is:  0.1250725142127857\n",
      "\n",
      "Recall of label  3.0  is:  1.1666666666666667\n",
      "Precision of label  3.0  is:  0.002199183160540371\n",
      "\n",
      "Recall of label  4.0  is:  0.4060303077644118\n",
      "Precision of label  4.0  is:  0.8941103619100041\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[3.8140e+03 1.3610e+03 1.4150e+03 4.4500e+02 1.3620e+03]\n",
      " [0.0000e+00 2.1700e+02 0.0000e+00 0.0000e+00 0.0000e+00]\n",
      " [2.2100e+02 2.1500e+02 1.0780e+03 1.5800e+02 2.5500e+02]\n",
      " [0.0000e+00 0.0000e+00 0.0000e+00 5.0000e+00 0.0000e+00]\n",
      " [6.2240e+03 4.0960e+03 6.1260e+03 2.6160e+03 1.2995e+04]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Random Forest and train the pipeline\n",
    "rf = RandomForestClassifier(labelCol=\"score\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"score\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(rf,\"text\")\n",
    "paramGrid = paramGrid.addGrid(rf.numTrees,[10, 100])\\\n",
    "    .addGrid(rf.maxDepth,[1, 10])\\\n",
    "    .build()\n",
    "    \n",
    "# Finally train the pipeline\n",
    "%time model_rf = trainPipeline(pipeline,evaluator,train_set,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_rf.transform(train_set)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_rf.transform(test_set)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0,3.0,4.0]\n",
    "evaluatePerformance(model_rf,test_set,\"score\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second experiment:** Classification of score using Naive Bayes on text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.23 s, sys: 872 ms, total: 5.1 s\n",
      "Wall time: 7min 56s\n",
      "Accuracy of the best fitted model on training set = 0.5694115583618347\n",
      "Accuracy of the best fitted model on test set = 0.541908400547144\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|score|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|The new flavor is...|  0.0|       0.0|\n",
      "|These noodles wer...|  0.0|       3.0|\n",
      "|Sunday breakfast ...|  0.0|       2.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 3.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.626675041876047\n",
      "Precision of label  0.0  is:  0.5834876693634857\n",
      "\n",
      "Recall of label  1.0  is:  0.34743969530258145\n",
      "Precision of label  1.0  is:  0.41823739174732555\n",
      "\n",
      "Recall of label  2.0  is:  0.47427588943261473\n",
      "Precision of label  2.0  is:  0.41605754727926675\n",
      "\n",
      "Recall of label  3.0  is:  0.22540900828115532\n",
      "Precision of label  3.0  is:  0.3422263109475621\n",
      "\n",
      "Recall of label  4.0  is:  0.7450833769535632\n",
      "Precision of label  4.0  is:  0.686084142394822\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[ 5986.  1197.  1202.   223.   944.]\n",
      " [ 2111.  2463.  1519.   273.   709.]\n",
      " [ 1056.  1245.  3586.   562.  1063.]\n",
      " [  357.   458.  1244.  1079.  1879.]\n",
      " [  749.   526.  1068.  1021. 10076.]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Naive Bayes and train the pipeline\n",
    "nb = NaiveBayes(labelCol=\"score\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"score\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(nb,\"text\")\n",
    "paramGrid = paramGrid.addGrid(nb.smoothing,[0.0,0.5,1.0])\\\n",
    "    .build()\n",
    "\n",
    "# Finally train the pipeline\n",
    "%time model_nb = trainPipeline(pipeline,evaluator,train_set,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_nb.transform(train_set)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_nb.transform(test_set)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0,3.0,4.0]\n",
    "evaluatePerformance(model_nb,test_set,\"score\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third experiment:** Classification of score using Logistic Regression on text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.03 s, sys: 1.85 s, total: 7.88 s\n",
      "Wall time: 14min 6s\n",
      "Accuracy of the best fitted model on training set = 0.6874846539689221\n",
      "Accuracy of the best fitted model on test set = 0.6256734818718679\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|score|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|The new flavor is...|  0.0|       0.0|\n",
      "|These noodles wer...|  0.0|       2.0|\n",
      "|Sunday breakfast ...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 2.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.669975412075403\n",
      "Precision of label  0.0  is:  0.7171264255775417\n",
      "\n",
      "Recall of label  1.0  is:  0.46549586776859503\n",
      "Precision of label  1.0  is:  0.3825776872134488\n",
      "\n",
      "Recall of label  2.0  is:  0.5434365250779938\n",
      "Precision of label  2.0  is:  0.5254669915303399\n",
      "\n",
      "Recall of label  3.0  is:  0.33608147429679924\n",
      "Precision of label  3.0  is:  0.21415327564894932\n",
      "\n",
      "Recall of label  4.0  is:  0.7270397266125588\n",
      "Precision of label  4.0  is:  0.8230174081237911\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[ 7357.  1556.  1145.   213.   723.]\n",
      " [ 1028.  2253.  1013.   181.   349.]\n",
      " [  913.  1273.  4529.   705.   964.]\n",
      " [  123.   159.   462.   660.   685.]\n",
      " [  838.   648.  1470.  1469. 11859.]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Logistic Regression and train the pipeline\n",
    "lr = LogisticRegression(labelCol=\"score\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"score\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(lr,\"text\")\n",
    "paramGrid = paramGrid.addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "# Finally train the pipeline\n",
    "%time model_lr = trainPipeline(pipeline,evaluator,train_set,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_lr.transform(train_set)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_lr.transform(test_set)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0,3.0,4.0]\n",
    "evaluatePerformance(model_lr,test_set,\"score\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Classification by sentiment \n",
    "\n",
    "As seen from the above experiment, performances of the best models are show a certain degree of correlation between the score and review, but not too strong. As it was mentioned previously, guessing the proper score may be tricky. Thus, information is aggregated into sentiments to provide a way of summarizing what is a clearly positive review ( 4 or 5) and what is a negative review (1 and 2) as well as a neutral category (3).\n",
    "\n",
    "Again, performance is evaluated thoroughly and the same three classification algorithms are used. Notice that 'positive' is labelled as 2.0, 'neutral' as 1.0 and 'negative' as 0.0, again for the purpose of the requirements of the techniques used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fourth experiment:** Classification of sentiment using Random Forest on text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 5.5 s, total: 19.9 s\n",
      "Wall time: 1h 4min 52s\n",
      "Accuracy of the best fitted model on training set = 0.6099812017966632\n",
      "Accuracy of the best fitted model on test set = 0.5990663413718682\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|The new flavor is...|  0.0|       0.0|\n",
      "|These noodles wer...|  0.0|       2.0|\n",
      "|Sunday breakfast ...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 2.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.6970960766141489\n",
      "Precision of label  0.0  is:  0.5589546693088927\n",
      "\n",
      "Recall of label  1.0  is:  1.0\n",
      "Precision of label  1.0  is:  0.005453068801485091\n",
      "\n",
      "Recall of label  2.0  is:  0.5592376954843951\n",
      "Precision of label  2.0  is:  0.927312528064661\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[ 9026.  2630.  1302.]\n",
      " [    0.    47.     0.]\n",
      " [ 7122.  5942. 16446.]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Random Forest and train the pipeline\n",
    "rf = RandomForestClassifier(labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"label\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(rf,\"text\")\n",
    "paramGrid = paramGrid.addGrid(rf.numTrees,[10, 100])\\\n",
    "    .addGrid(rf.maxDepth,[1, 10])\\\n",
    "    .build()\n",
    "    \n",
    "# Finally train the pipeline\n",
    "%time model_rf_sentiment = trainPipeline(pipeline,evaluator,train_set,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_rf_sentiment.transform(train_set)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_rf_sentiment.transform(test_set)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0]\n",
    "evaluatePerformance(model_rf_sentiment,test_set,\"label\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fifth experiment:** Classification of sentiment using Naive Bayes on text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.41 s, sys: 1.41 s, total: 6.82 s\n",
      "Wall time: 8min 44s\n",
      "Accuracy of the best fitted model on training set = 0.6941867402927103\n",
      "Accuracy of the best fitted model on test set = 0.6819575471698113\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|The new flavor is...|  0.0|       0.0|\n",
      "|These noodles wer...|  0.0|       2.0|\n",
      "|Sunday breakfast ...|  0.0|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 2.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.7311040486389387\n",
      "Precision of label  0.0  is:  0.6553133514986376\n",
      "\n",
      "Recall of label  1.0  is:  0.4396887159533074\n",
      "Precision of label  1.0  is:  0.5637544958811928\n",
      "\n",
      "Recall of label  2.0  is:  0.7850856606430415\n",
      "Precision of label  2.0  is:  0.7552633064288536\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[10582.  2078.  1816.]\n",
      " [ 3707.  4859.  2574.]\n",
      " [ 1859.  1682. 13304.]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Naive Bayes and train the pipeline\n",
    "nb = NaiveBayes(labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"label\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(nb,\"text\")\n",
    "paramGrid = paramGrid.addGrid(nb.smoothing,[0.0,0.5,1.0])\\\n",
    "    .build()\n",
    "\n",
    "# Finally train the pipeline\n",
    "%time model_nb_sentiment = trainPipeline(pipeline,evaluator,train_set,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_nb_sentiment.transform(train_set)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_nb_sentiment.transform(test_set)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0]\n",
    "evaluatePerformance(model_nb_sentiment,test_set,\"label\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sixth experiment:** Classification of sentiment using Logistic Regression on text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.3 s, sys: 2.35 s, total: 10.7 s\n",
      "Wall time: 13min 23s\n",
      "Accuracy of the best fitted model on training set = 0.7738628335892481\n",
      "Accuracy of the best fitted model on test set = 0.7403932292894526\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|The new flavor is...|  0.0|       0.0|\n",
      "|These noodles wer...|  0.0|       2.0|\n",
      "|Sunday breakfast ...|  0.0|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 2.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.7472533928676341\n",
      "Precision of label  0.0  is:  0.7876517215754273\n",
      "\n",
      "Recall of label  1.0  is:  0.5815549917922698\n",
      "Precision of label  1.0  is:  0.45214061956143403\n",
      "\n",
      "Recall of label  2.0  is:  0.7830253613596654\n",
      "Precision of label  2.0  is:  0.8312629981451296\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[12719.  2561.  1739.]\n",
      " [ 1569.  3897.  1261.]\n",
      " [ 1860.  2161. 14800.]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Logistic Regression and train the pipeline\n",
    "lr = LogisticRegression(labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"label\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(lr,\"text\")\n",
    "paramGrid = paramGrid.addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "# Finally train the pipeline\n",
    "%time model_lr_sentiment = trainPipeline(pipeline,evaluator,train_set,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_lr_sentiment.transform(train_set)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_lr_sentiment.transform(test_set)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0]\n",
    "evaluatePerformance(model_lr_sentiment,test_set,\"label\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Comparison of models downsampled\n",
    "\n",
    "The best approach (Logistic Regression) is compared with the models trained with less data to show how the models perform when feeded with less data. We want to see how the behaviour of the models change with different amount of data used in training.\n",
    "\n",
    "Ideally, if a smaller amount of data is representative enough, adding more data will not improve the global performance of the model. However, in practice the latter case seems to be the correct one. We will see if that applies to our dataset. The analysis is performed in the best model obtained up to now.\n",
    "\n",
    "**Seventh experiment:** Classification of sentiment using Logistic Regression on text column (downsampled dataset 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.38 s, sys: 820 ms, total: 4.2 s\n",
      "Wall time: 54.3 s\n",
      "Accuracy of the best fitted model on training set = 0.7410468319559229\n",
      "Accuracy of the best fitted model on test set = 0.5906348831720557\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|White peaches are...|  0.0|       0.0|\n",
      "|I purchased this ...|  0.0|       0.0|\n",
      "|I hate to rag on ...|  0.0|       0.0|\n",
      "|No flavor at all....|  0.0|       0.0|\n",
      "|Here is the MIO P...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.607282335353629\n",
      "Precision of label  0.0  is:  0.6453253534308655\n",
      "\n",
      "Recall of label  1.0  is:  0.3449001702522829\n",
      "Precision of label  1.0  is:  0.263878363016294\n",
      "\n",
      "Recall of label  2.0  is:  0.662249661195603\n",
      "Precision of label  2.0  is:  0.6988558975755925\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[52403. 16479. 17480.]\n",
      " [11866. 11142.  9390.]\n",
      " [16935. 14603. 61248.]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Logistic Regressor and train the pipeline\n",
    "lr = LogisticRegression(labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"label\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(nb,\"text\")\n",
    "paramGrid = paramGrid.addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "# Finally train the pipeline\n",
    "%time model_lr_small1 = trainPipeline(pipeline,evaluator,train_small_1,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_lr_small1.transform(train_small_1)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_lr_small1.transform(test_small_1)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0]\n",
    "evaluatePerformance(model_lr_small1,test_small_1,\"label\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eigth experiment:** Classification of sentiment using Logistic Regression on text column (downsampled dataset 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.12 s, sys: 996 ms, total: 5.11 s\n",
      "Wall time: 1min 50s\n",
      "Accuracy of the best fitted model on training set = 0.6762430417963959\n",
      "Accuracy of the best fitted model on test set = 0.6468542770154732\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|White peaches are...|  0.0|       0.0|\n",
      "|I purchased this ...|  0.0|       0.0|\n",
      "|I hate to rag on ...|  0.0|       0.0|\n",
      "|No flavor at all....|  0.0|       1.0|\n",
      "|Here is the MIO P...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 1.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.6898362681495211\n",
      "Precision of label  0.0  is:  0.6639635621511306\n",
      "\n",
      "Recall of label  1.0  is:  0.40606762389995366\n",
      "Precision of label  1.0  is:  0.4558548252911814\n",
      "\n",
      "Recall of label  2.0  is:  0.7439396843652163\n",
      "Precision of label  2.0  is:  0.7289882294014526\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[49126. 11613. 10305.]\n",
      " [14430. 17534. 11238.]\n",
      " [10433.  9317. 58194.]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Logistic Regression and train the pipeline\n",
    "lr = LogisticRegression(labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"label\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(nb,\"text\")\n",
    "paramGrid = paramGrid.addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "# Finally train the pipeline\n",
    "%time model_lr_small2 = trainPipeline(pipeline,evaluator,train_small_2,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_lr_small2.transform(train_small_2)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_lr_small2.transform(test_small_2)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0]\n",
    "evaluatePerformance(model_lr_small2,test_small_2,\"label\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Effect of classification on summary\n",
    "\n",
    "The last experiment consists of analyzing the summary instead of the whole text. Summary is supposed to condense the information about user's degree of acceptability of the product. Thus, if a model fitted to the summary works well, the computational complexity of the model will go down, as long as the system is processing a considerable less amount of words. Again, the technique is applied over the best performing model: Logistic Regression on sentiment analysis.\n",
    "\n",
    "**Ninth experiment:** Classification of sentiment using Logistic Regression on summary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.04 s, sys: 948 ms, total: 4.98 s\n",
      "Wall time: 1min 44s\n",
      "Accuracy of the best fitted model on training set = 0.6859303711619877\n",
      "Accuracy of the best fitted model on test set = 0.6588888366185257\n",
      "\n",
      "\n",
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|We bought a carto...|  0.0|       0.0|\n",
      "|The new flavor is...|  0.0|       0.0|\n",
      "|These noodles wer...|  0.0|       0.0|\n",
      "|Sunday breakfast ...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]\n",
      "\n",
      "Recall of label  0.0  is:  0.7133891213389121\n",
      "Precision of label  0.0  is:  0.6335149863760218\n",
      "\n",
      "Recall of label  1.0  is:  0.44018638265500193\n",
      "Precision of label  1.0  is:  0.537069265576053\n",
      "\n",
      "Recall of label  2.0  is:  0.7386574987318942\n",
      "Precision of label  2.0  is:  0.736168061562658\n",
      "\n",
      "Confusion Matrix: \n",
      "\n",
      "[[10230.  2000.  2063.]\n",
      " [ 3244.  4629.  2606.]\n",
      " [ 2674.  1990. 13105.]]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Logistic Regression and train the pipeline\n",
    "lr = LogisticRegression(labelCol=\"label\")\n",
    "evaluator = MulticlassClassificationEvaluator().setMetricName(\"accuracy\").setLabelCol(\"label\")\n",
    "\n",
    "# Set pipeline and grid of general parameters. Add the parameters of the model\n",
    "pipeline, paramGrid = setPipeline(nb,\"summary\")\n",
    "paramGrid = paramGrid.addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "# Finally train the pipeline\n",
    "%time model_lr_summary = trainPipeline(pipeline,evaluator,train_set,paramGrid)\n",
    "print(\"Accuracy of the best fitted model on training set =\",evaluator.evaluate(model_lr_summary.transform(train_set)))\n",
    "print(\"Accuracy of the best fitted model on test set =\",evaluator.evaluate(model_lr_summary.transform(test_set)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Advanced test\n",
    "possibleLabels = [0.0,1.0,2.0]\n",
    "evaluatePerformance(model_lr_summary,test_set,\"label\",possibleLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Conclusions\n",
    "\n",
    "1) First of all, the comparison between the three models in score classificaton is interesting. Although Random Forest is the more complex model and it should be able of capturing more complex patterns, it does a really poor job in comparison with more simple and linear approaches such as Logistic Regression and Naive Bayes (42% vs 62% and 54% respectively in test set). However, not only accuracy is the only aspect to check. Training time is significantly longer with Random Forest (58 min vs 7 min and 14 min respectively). Thus, the size effect starts to become significant: when data increases, simple models would still work surprisingly good, sometimes even outperform more complex models. In the case of this project, Logistic Regression is the best performing model.\n",
    "\n",
    "2) Another interesting point of the score classification can be seen in the confusion matrix. Precision and recall is higher in both extreme scores: 1 and 5. One possible explanation is the fact that extremely good or bad reviews (and vocabulary) is translated into the best or worse possible score. Central scores would be related with more vague and abstract use of the language. This is one of the reasons why it was decided to summarize scores into sentiments. Negative and positive vocabulary will be more distinguishable.\n",
    "\n",
    "3) The sentiment analysis performs better than predicting rating in terms of accuracies of the three models. The best performing model (Logistic Regression) scores a decent degree of accuracy: 74% in test set. This means 12 more points compared with the score prediction. Again, prediction of positive and negative values is better than the neutral ones. Indeed, precision of positive and negative labels is nearly 80%.\n",
    "\n",
    "4) Regarding the downsampled experiments some insights can be obtained. Downsampled dataset are roughly 1% and 10% of the initial dataset. It can be seen the instability of the model trained in the 1% downsampled dataset: training accuracy is almost the same as the total model but the generalization to test examples fails dramatically ( 54% accuracy). This dataset is clearly too small as to map decently the reviews space. If we use the 10% downsampled dataset it can be seen more stable results: training are test accuracies are similar. However, these accuracies are almost 10 points below the accuracy obtained by the model in the full dataset (64% vs 74% in test set). Theoretically, if the dataset is representative, more data is not needed. But from this experiment it shows that in practice more data can lead to better results.\n",
    "\n",
    "5) It is interesting to take a look at training times in downsampled models. Although the increasing of time between 10% downsampled dataset and the full dataset seems to be linear (from 1min 45 s to 14 min), this does not apply to the 1% downsampled dataset. Training times of both downsampled models are roughly the same. Distributed systems reduce computation times but there is a minimum computation cost to pay: parallel computation is designed to solve large data problems.\n",
    "\n",
    "6) Finally, sentiment classification is tried in the summary of the review. Although the comparison is not effective in terms of accuracy (65% vs 74% using the complete review), training time is reduced dramatically. We are processing less amount of data and thus, for some situations, it can be effective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
